#tema/fundamentals 

# DynamicFrame vs DataFrame
## **1. DataFrame (Spark puro)**
- Estrutura **tabular**, organizada em linhas e colunas.
- Schema r√≠gido (tipos de dados bem definidos).
- Excelente para dados **estruturados** (ex: tabelas CSV limpas, Parquet).
- Se encontrar inconsist√™ncias de schema ‚Üí geralmente d√° erro (ex: string onde deveria ser inteiro).
---
## **2. DynamicFrame (Glue)**
- √â uma abstra√ß√£o do Glue sobre o Spark DataFrame.
- Guarda **metadados adicionais de ETL**, como:
    - Informa√ß√µes de origem do dado.
    - Transforma√ß√µes aplicadas.
    - Hist√≥rico de erros de convers√£o de schema.
- Mais tolerante a **schemas semi-estruturados** ou **dados inconsistentes**.
- Permite manipula√ß√£o de campos aninhados e dados com m√∫ltiplos tipos sem falhar imediatamente.
- Converte para DataFrame quando voc√™ precisa usar APIs Spark puras (`toDF()`), e pode voltar para DynamicFrame (`fromDF()`).

üëâ Pense no DynamicFrame como um **DataFrame com intelig√™ncia extra para ETL**.

---
## **3. DynamicRecord**
- Cada **linha** de um DynamicFrame √© representada como um **DynamicRecord**.
- Diferente de uma linha de DataFrame (que √© s√≥ uma tupla com tipos fixos), o DynamicRecord √© **auto-descritivo**:
    - Cada campo tem metadados de tipo e origem.
    - Pode conter **estruturas aninhadas** (ex: JSON complexo).
    - Permite acessar campos de forma segura sem quebrar o job caso um campo esteja ausente.

Exemplo simplificado:
``` Python
# DynamicRecord pode ter campos irregulares:
{
  "id": 101,
  "price": "45.7",   # string
  "tags": ["promo", "outlet"]
}

{
  "id": 102,
  "price": 45.7,     # float
  "tags": None
}

```

Um DataFrame do Spark teria problemas com esse `price` (string vs float).  
Um DynamicFrame lida com isso ‚Üí voc√™ pode aplicar `resolveChoice("cast:double")` para unificar.

---
## **4. Resumindo**
- **DynamicFrame** ‚Üí cole√ß√£o distribu√≠da de DynamicRecords, projetada para ETL, flex√≠vel com schemas inconsistentes.
- **DynamicRecord** ‚Üí linha auto-descritiva, permite manipula√ß√£o de dados aninhados ou irregulares sem quebrar o pipeline.
- **DataFrame** ‚Üí melhor para performance e opera√ß√µes SQL/anal√≠ticas cl√°ssicas, mas exige schema consistente.
---
Dica de prova:  
Se a quest√£o falar em **dados semi-estruturados, JSON aninhado ou schema inconsistente** ‚Üí escolha **DynamicFrame**.  
Se falar em **opera√ß√µes Spark SQL, joins complexos ou performance** ‚Üí converta para **DataFrame**.
