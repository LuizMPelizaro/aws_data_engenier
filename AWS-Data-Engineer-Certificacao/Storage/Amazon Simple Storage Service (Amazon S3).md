#tema/storage
# Amazon Simple Storage Service (Amazon S3)
O Amazon S3 (Simple Storage Service) √© um dos **servi√ßos fundamentais** da Amazon Web Services (AWS) e serve como um **bloco de constru√ß√£o essencial** para a maioria das arquiteturas em nuvem. Ele oferece um **armazenamento de objetos escal√°vel de forma praticamente infinita**, sendo a espinha dorsal de grande parte da web moderna e de in√∫meros servi√ßos da AWS.

---
## O que √© ?

* **Servi√ßo de Armazenamento de Objetos:** O S3 √© projetado para armazenar e recuperar **qualquer quantidade de dados**, a qualquer momento e de qualquer lugar na web. Ele n√£o √© um sistema de arquivos tradicional, mas sim um servi√ßo de armazenamento de objetos. 
* **Escalabilidade Infinita:** Sua principal caracter√≠stica √© a capacidade de escalar para petabytes, exabytes e al√©m, sem a necessidade de provisionar ou gerenciar infraestrutura de armazenamento subjacente. 
* **Backbone da Web:** Muitos sites, aplicativos e servi√ßos online dependem do S3 para armazenar seus dados, desde arquivos est√°ticos at√© grandes volumes de dados de logs e conte√∫do de m√≠dia. 
* **Integra√ß√£o com Servi√ßos AWS:** O S3 se integra nativamente com a vasta maioria dos outros servi√ßos da AWS, atuando como um ponto central de armazenamento para fluxos de trabalho complexos e an√°lises de dados.
## Casos de uso
O S3 √© incrivelmente vers√°til e suporta uma ampla gama de casos de uso, tornando-o indispens√°vel para engenheiros de dados:
* **Backup e Armazenamento:** √â um destino ideal para backups de dados de bancos de dados, servidores e aplica√ß√µes, garantindo durabilidade e disponibilidade. 
* **Recupera√ß√£o de Desastres:** Permite a replica√ß√£o de dados entre diferentes regi√µes da AWS, assegurando a recupera√ß√£o de dados e a continuidade dos neg√≥cios em caso de falha de uma regi√£o. 
* **Arquivamento de Dados:** Com classes de armazenamento otimizadas para arquivamento (como o S3 Glacier), √© poss√≠vel armazenar grandes volumes de dados por longos per√≠odos a um custo muito baixo, com op√ß√µes de recupera√ß√£o flex√≠veis. 
* **Armazenamento H√≠brido:** Facilita a extens√£o da capacidade de armazenamento local para a nuvem, criando solu√ß√µes de armazenamento h√≠bridas sem a necessidade de expandir a infraestrutura f√≠sica. 
* **Hospedagem de Aplicativos e Sites Est√°ticos:** Pode ser usado para hospedar arquivos est√°ticos para sites e aplica√ß√µes web, oferecendo alta disponibilidade e escalabilidade. * **M√≠dia:** Armazenamento eficiente de arquivos de m√≠dia (imagens, v√≠deos, √°udio) para consumo por aplica√ß√µes e usu√°rios. 
* **Data Lakes e An√°lise de Big Data:** √â a **base fundamental para a constru√ß√£o de Data Lakes**. Engenheiros de dados utilizam o S3 para centralizar dados brutos e refinados de diversas fontes, que s√£o ent√£o processados e analisados por servi√ßos como AWS Athena, AWS Glue e Amazon EMR. 
* **Atualiza√ß√£o de Software:** Distribui√ß√£o de atualiza√ß√µes de software e firmware para dispositivos e aplica√ß√µes.
### Exemplo 
**Exemplos Not√°veis:**  
A **NASDAQ** armazena sete anos de dados hist√≥ricos no **S3 Glacier**, aproveitando seu baixo custo para arquivamento de longo prazo. 
A **Sysco** utiliza o S3 como base para suas an√°lises de dados, obtendo insights de neg√≥cios cr√≠ticos a partir de seus vastos volumes de informa√ß√µes.

---
## Amazon S3- Buckets
No S3, seus dados s√£o organizados em **Buckets**. Pense nos buckets como cont√™ineres de n√≠vel superior ou diret√≥rios raiz para seus objetos.

* **Estrutura de Armazenamento:** Os buckets funcionam como os principais organizadores de seus dados no S3.
* **Nomenclatura Globalmente √önica:** Um dos aspectos mais **cr√≠ticos** e frequentemente confundidos do S3 √© que o nome de um bucket deve ser **globalmente √∫nico**. Isso significa que nenhum outro bucket, em nenhuma outra conta da AWS e em nenhuma outra regi√£o do mundo, pode ter o mesmo nome. **Esta √© a √∫nica entidade na AWS que exige unicidade global em seu nome.** 
* **Defini√ß√£o Regional:** Apesar da unicidade global do nome, os buckets s√£o **criados em uma regi√£o espec√≠fica**. Embora o S3 pare√ßa um servi√ßo global do ponto de vista da nomenclatura, a resid√™ncia f√≠sica dos dados dentro de um bucket √© sempre regional. Isso √© **importante para considera√ß√µes de lat√™ncia, conformidade e custos.**
### **Conven√ß√µes de Nomenclatura para Buckets:** 
√â fundamental seguir estas regras para nomes de buckets: 
* N√£o podem conter letras mai√∫sculas ou sublinhados (`_`). 
* Devem ter entre 3 e 63 caracteres de comprimento. 
* N√£o podem ser formatados como endere√ßos IP (ex: `192.168.1.1`). 
* Devem come√ßar com uma letra min√∫scula ou um n√∫mero.
* N√£o podem come√ßar com o prefixo `xn--`. 
* N√£o podem terminar com o sufixo `-s3alias`.
---
## S3 Object
Os arquivos que voc√™ armazena dentro de um bucket S3 s√£o chamados de **Objetos**.
**Chave do Objeto (Key):** Cada objeto no S3 possui uma **chave √∫nica**. 
* A chave √© o **caminho completo** (full path) do objeto dentro do bucket.
	* Exemplo: `s3://my-bucket/my_file.txt` (onde `my_file.txt` √© a chave) 
	* Exemplo: `s3://my-bucket/my_folder/another_folder/my_file.txt` (a chave √© `my_folder/another_folder/my_file.txt`)
* **Prefixos e Nomes de Objeto:** A chave √© conceitualmente composta por um **prefixo** e o **nome do objeto (arquivo)**. 
	* Exemplo: `s3://my-bucket/my_folder/another_folder/my_file.txt`
	* **Prefixo:** `my_folder/another_folder/`
	* **Nome do Objeto:** `my_file.txt`
* **Sem Conceito de Diret√≥rios Reais:** √â crucial entender que o S3 **n√£o possui um conceito de "diret√≥rios" ou "pastas" reais** como em um sistema de arquivos tradicional. A interface do S3 (console, ferramentas) simula diret√≥rios para facilitar a visualiza√ß√£o, mas, na realidade, tudo √© armazenado como objetos planos com chaves que cont√™m barras. As barras s√£o apenas parte do nome da chave e s√£o usadas para organizar logicamente os objetos. 
	* Ou seja, ao criar uma "pasta" no console S3, voc√™ est√°, na verdade, definindo um prefixo comum para um grupo de chaves de objetos.
	* 
**MAS TUDO E QUALQUER COISA NO S3 NA VERDADE S√ÉO CHAVES**
---
## Conte√∫do e Metadados de Objetos S3 
Os objetos S3 n√£o s√£o apenas os dados em si; eles tamb√©m cont√™m informa√ß√µes adicionais:
* **Valores do Objeto (Body):** O valor do objeto √© o **conte√∫do bin√°rio real** do arquivo que est√° sendo armazenado. 
	* **Tamanho M√°ximo:** O tamanho m√°ximo de um √∫nico objeto √© **5 TB (Terabytes)**. 
	* **Upload Multipart:** Para objetos maiores que 5 GB, √© **obrigat√≥rio** utilizar o **"Multi-part Upload"**. Este m√©todo divide o objeto em partes menores, que s√£o carregadas individualmente e depois remontadas pelo S3. Isso melhora a resili√™ncia e a velocidade do upload. 
* **Metadata (Metadados):** S√£o pares de chave-valor que fornecem informa√ß√µes sobre o objeto.
	* Podem ser **definidos pelo sistema** (ex: `Content-Type`, `Last-Modified`) ou **pelo usu√°rio** (ex: `x-amz-meta-department: finance`).
	* Esses metadados s√£o √∫teis para descrever o conte√∫do do objeto ou para aplica√ß√µes que precisam de informa√ß√µes adicionais sem acessar o conte√∫do completo do arquivo. 
* **Tags:** S√£o pares de chave-valor (Unicode) que podem ser anexados a objetos (at√© 10 tags por objeto). 
	* S√£o amplamente utilizados para **gerenciamento de seguran√ßa** (controle de acesso baseado em tags) e para **pol√≠ticas de ciclo de vida** (ex: mover objetos para armazenamento mais barato ap√≥s um certo tempo com base em tags). 
* **ID de Vers√£o:** Se o **versionamento** estiver ativado no bucket, cada vers√£o de um objeto ter√° um ID de vers√£o √∫nico. Isso permite que voc√™ mantenha v√°rias vers√µes do mesmo objeto e recupere vers√µes anteriores, protegendo contra exclus√µes acidentais ou sobrescritas.
---
## Hands-on: Criando e Utilizando um Bucket S3 na AWS
Criar um bucket no S3 √© um processo simples e direto via Console da AWS:
1. Acesse sua conta AWS.
2. No campo de pesquisa, digite `S3` e selecione o servi√ßo.
3. Clique em **"Criar bucket"**.
4. Defina um **nome √∫nico globalmente** (nome exclusivo entre todas as contas e regi√µes da AWS).
5. Escolha a **regi√£o** apropriada ‚Äî o bucket ser√° criado na **regi√£o atualmente selecionada no console**.

Ap√≥s subir um arquivo para o bucket, a AWS fornece uma **URL p√∫blica**. No entanto, ao tentar acess√°-la diretamente, voc√™ provavelmente ver√° uma mensagem de **"Access Denied"**:
Isso ocorre porque, por padr√£o, os objetos no S3 n√£o s√£o p√∫blicos e **requerem credenciais de acesso v√°lidas**.

![[Pasted image 20250726124606.png]]

Se voc√™ tentar abrir o arquivo diretamente pelo bot√£o **"Abrir"** dentro do Console da AWS, o acesso √© bem-sucedido. Isso acontece porque o console **anexa temporariamente as credenciais necess√°rias** (assinatura com token de acesso) √† URL ao realizar a requisi√ß√£o.

---
### Organiza√ß√£o do Bucket
- √â poss√≠vel criar **pastas virtuais** dentro do bucket, funcionando de forma semelhante ao Dropbox ou Google Drive.
- Tamb√©m √© poss√≠vel:
    - **Mover**
    - **Renomear**
    - **Excluir** arquivos e pastas
Como essas a√ß√µes s√£o bastante intuitivas, e j√° as realizei diversas vezes em ambiente de trabalho, n√£o entrarei em detalhes passo a passo.
---
### Observa√ß√µes Importantes
- Buckets s√£o regionais, mas o nome deve ser **√∫nico globalmente**.
- O acesso a arquivos depende das **pol√≠ticas de bucket, permiss√µes de objeto** e **configura√ß√µes de seguran√ßa** (como bloqueio de acesso p√∫blico).
- Para acesso p√∫blico, ser√° necess√°rio configurar:
    - Permiss√µes de bucket e objeto
    - Pol√≠ticas p√∫blicas expl√≠citas    
    - Desbloqueio do "Bloqueio de Acesso P√∫blico"

## S3 - Seguran√ßa

### Baseada em usu√°rios
* IAM Policies - chamadas de API devem ser permitidas para um usu√°rio especifico
### Baseada em recursos
* Bucket Policies - pol√≠ticas de bucket do S3 e h√° regras para todo o bucket que podem ser atribu√≠das diretamente no console do S3 - cross-account.
	* Isso permitira que um usuario especifico entre ou permita que um usuario de outra conta isso √© chamado de cross-account
* Object Access Control  List (ACL)- √â uma seguran√ßa mais fina e pode ser desativada.
* Bucket Access Control  List (ACL)- Pouco comum e tambem pode ser desativado

#### Nota : Em que situa√ß√µes um principio de IAM pode acessar um objeto S3 ?
* As permiss√µes IAM do usu√°rio PERMITEM OU a pol√≠tica de recursos PERMITE
* E n√£o h√° NEGA√á√ÉO expl√≠cita
### Criptografia: objetos criptografados no S3 usam chaves de criptografia

## Politica de Buckets S3
* Politicas baseadas em JSON 
	* `Resources`: buckets e objetos, nesse exemplo podemos ver que isso se aplica a todos os objetos do bucket 
	* `Effect`: Allow/Deny , o que permitimos ou negamos as a√ß√£o (actions)
	* `Actions`: Um conjunto de API que podemos permitir ou negar. No nosso exemplo pemitiomos o GetObject
	* `Principal`: As contas ou usuarios que aplicamos a politica
	* `Statement`: Lista de declara√ß√£o de permiss√£o. Pode haver uma ou mais.

Essa pol√≠tica permite que **qualquer pessoa na internet** acesse (fa√ßa **download**) de qualquer arquivo armazenado no bucket `exemplebucket`.
```json
{
	"Version": "2012-10-17",
	"Statement": [
		{
			"Sid": "PublicRead",
			"Effect": "Allow",
			"Principal": "*",
			"Action":[
				"s3:GetObject"
			],
			"Resource": [
				"arn:aws:s3:::exemplebucket/*"
			]
		}
	]

}
```
### Usamos politicas de bucket para:
* Garantir acesso publico ao bucket (como o acima)
* For√ßa objetos a serem criptografados no upload
* Ou para conceder acesso a uma outra conta
## Bloqueio de Acesso P√∫blico no S3
A configura√ß√£o de **bloqueio de acesso p√∫blico** foi criada para **evitar vazamentos acidentais de dados** em buckets S3.
![[Pasted image 20250726134811.png]]
### üîí Como Funciona
- Mesmo que uma **pol√≠tica de bucket** permita acesso p√∫blico, o acesso **ser√° negado** se o bloqueio estiver ativado.
- **O bloqueio sobrescreve qualquer configura√ß√£o p√∫blica.**
### ‚úÖ Quando Usar
- Ative **sempre que o bucket n√£o deve ser p√∫blico**.
- Ideal para ambientes **corporativos e de produ√ß√£o**.
### üè¢ N√≠vel de Conta
- Pode ser aplicado em **n√≠vel de conta**, impedindo que **qualquer bucket** da conta se torne p√∫blico.
### Exemplos de regras (todas nos slide do curso)
### üßë‚Äçüíª Exemplo 1 ‚Äî Acesso P√∫blico via Pol√≠tica de Bucket

Quando temos um usu√°rio externo (visitante da web global) tentando acessar arquivos armazenados em nossos buckets S3, podemos **habilitar o acesso p√∫blico** ao bucket ou a objetos espec√≠ficos por meio de uma **pol√≠tica de bucket**.

> ‚ö†Ô∏è **Aten√ß√£o:** Habilitar acesso p√∫blico requer cautela, pois pode expor dados sens√≠veis.

---
### üßë‚Äçüíº Exemplo 2 ‚Äî Acesso via Pol√≠tica IAM (usu√°rio da mesma conta)

Se tivermos um **usu√°rio IAM na mesma conta AWS** que precisa acessar objetos no Amazon S3, podemos **atribuir uma pol√≠tica IAM** diretamente a esse usu√°rio, concedendo as permiss√µes necess√°rias.

Com isso, o usu√°rio ser√° capaz de realizar opera√ß√µes em buckets ou objetos conforme definido na pol√≠tica (por exemplo, `s3:GetObject`, `s3:PutObject`).

---
### üìÇ Exemplo 3 ‚Äî Pol√≠tica IAM com Permiss√£o para Buckets Espec√≠ficos

Outra maneira similar ao Exemplo 2: ao criar uma **pol√≠tica IAM que permita o acesso a buckets espec√≠ficos**, o usu√°rio IAM poder√° acessar os recursos S3 conforme as permiss√µes definidas.
Essa pol√≠tica pode incluir permiss√µes como:
```json
{
  "Effect": "Allow",
  "Action": "s3:*",
  "Resource": [
    "arn:aws:s3:::nome-do-bucket",
    "arn:aws:s3:::nome-do-bucket/*"
  ]
}
```
### üíª Exemplo 4 ‚Äî Acesso via Fun√ß√£o IAM para Inst√¢ncia EC2

Quando precisamos permitir que uma **inst√¢ncia EC2 acesse um bucket S3**, **usu√°rios IAM n√£o s√£o ideais**. Em vez disso, devemos:
1. Criar uma **fun√ß√£o IAM com permiss√µes apropriadas ao S3**.
2. Anexar essa fun√ß√£o ao perfil da inst√¢ncia EC2.
Com isso, a inst√¢ncia poder√° acessar o S3 diretamente, utilizando as permiss√µes da fun√ß√£o.

---
### üîÑ Exemplo 5 ‚Äî Acesso entre Contas AWS (Cross-Account)

Para permitir o acesso a um bucket S3 por um **usu√°rio IAM de outra conta AWS**, devemos usar uma **pol√≠tica de bucket** com permiss√µes de acesso cruzado.

Exemplo:
```json
{
  "Effect": "Allow",
  "Principal": {
    "AWS": "arn:aws:iam::ID_DA_OUTRA_CONTA:root"
  },
  "Action": "s3:GetObject",
  "Resource": "arn:aws:s3:::nome-do-bucket/*"
}
```
Com isso, o usu√°rio IAM da conta externa poder√° realizar chamadas de API no bucket, conforme autorizado.
## Amazon S3 ‚Äî Versionamento
O **versionamento no Amazon S3** permite manter m√∫ltiplas vers√µes de um mesmo objeto dentro de um bucket. √â uma funcionalidade essencial para **prote√ß√£o de dados, recupera√ß√£o e auditoria**.

---
### ‚öôÔ∏è Como Funciona
- √â uma **configura√ß√£o no n√≠vel do bucket**.
- Ao **reatualizar (upload)** um objeto com o mesmo nome, o S3 **n√£o sobrescreve** o objeto antigo ‚Äî ele cria uma **nova vers√£o**.
- As vers√µes s√£o identificadas por um **ID exclusivo** atribu√≠do automaticamente.
- A primeira vers√£o antes do versionamento ativado recebe o **ID nulo** (`null`).
---
### ‚úÖ Boas Pr√°ticas

- **Habilitar versionamento √© altamente recomendado** em ambientes de produ√ß√£o.
- Benef√≠cios:
    - Protege contra **exclus√£o acidental** de dados.
    - Permite **rollback r√°pido** para vers√µes anteriores.
    - Suporta **auditoria e hist√≥rico de altera√ß√µes**.

---
### üßæ Comportamentos Importantes
- **Objetos pr√©-existentes** ao versionamento possuem vers√£o `null`.
- **Suspender o versionamento**:
    - N√£o remove vers√µes existentes.
    - Novos uploads ter√£o novamente vers√£o `null`.
- **Excluir um objeto versionado**:
    - Cria um **marcador de exclus√£o**.
    - Se voc√™ **remover o marcador**, a vers√£o anterior volta a ser acess√≠vel.

## Amazon S3 ‚Äì Replica√ß√£o (CRR e SRR)
O Amazon S3 oferece dois tipos de replica√ß√£o para copiar objetos de um bucket para outro de forma **ass√≠ncrona**:
- **CRR (Cross-Region Replication)**: replica√ß√£o entre **regi√µes diferentes**
- **SRR (Same-Region Replication)**: replica√ß√£o dentro da **mesma regi√£o**
---
### ‚öôÔ∏è Requisitos para Configurar a Replica√ß√£o
1. **Habilitar o versionamento** em ambos os buckets (origem e destino)
2. **Permiss√µes IAM adequadas**:
    - O S3 deve ter permiss√µes para **ler no bucket de origem** e **gravar no bucket de destino**
3. (Opcional) **Buckets podem estar em contas diferentes**

---
### üì¶ Funcionamento

- A replica√ß√£o √© feita de forma **ass√≠ncrona**
- Apenas **novos objetos e vers√µes** s√£o replicados (n√£o √© retroativo)
	- Caso queira replicar objetos antigos e objetos que tiverem a replica√ß√£o falha √© necess√°rio usar o S3 Batch Replication
- Voc√™ pode aplicar **filtros de replica√ß√£o** com base em prefixos ou tags
- Objetos replicados mant√™m **metadados e versionamento**
- N√£o replica objetos com **vers√£o null** (sem versionamento)
- N√£o √© feito a replica√ß√£o em cadeia 
- Somente marcadores de exclus√£o s√£o replicados, exclus√µes n√£o. **Lembrar do exemplo**
---
### Casos de Uso

#### ‚úÖ **CRR ‚Äì Cross-Region Replication**
- Redund√¢ncia geogr√°fica (resili√™ncia a falhas regionais)
- Redu√ß√£o de lat√™ncia para acesso em outras regi√µes
- Conformidade com requisitos regulat√≥rios
- Replica√ß√£o entre contas para isolamento ou backup
#### ‚úÖ **SRR ‚Äì Same-Region Replication**
- Agrupamento de logs de diferentes aplica√ß√µes/buckets
- Replica√ß√£o em tempo real para ambientes de **teste ou desenvolvimento**
- Backup gerenciado em outro bucket da mesma regi√£o

## Amazon S3 ‚Äì Classes de Armazenamento

No Amazon S3, ao armazenar um objeto, voc√™ pode escolher a **classe de armazenamento** com base em crit√©rios como frequ√™ncia de acesso, custo e necessidade de durabilidade. Tamb√©m √© poss√≠vel definir **regras de ciclo de vida (lifecycle rules)** para movimentar objetos entre classes automaticamente.

---
### Durabilidade e Disponibilidade

#### Durabilidade
- Todas as classes de armazenamento (exceto casos espec√≠ficos) oferecem **durabilidade de 99.999999999% (11 9's)**.
- A expectativa de perda de dados √© de **1 objeto em 10 milh√µes a cada 10 mil anos**.
- Armazenamento distribu√≠do entre m√∫ltiplas zonas de disponibilidade (AZs).

#### Disponibilidade
- Refere-se ao tempo em que o servi√ßo est√° operacional.
- A disponibilidade varia conforme a classe de armazenamento:
    - **S3 Standard**: 99.99% (at√© 53 minutos de indisponibilidade por ano)
    - **S3 Standard-IA**: 99.9%
    - **S3 One Zone-IA**: 99.5%

---

## Classes de Armazenamento
### S3 Standard
- Alta disponibilidade: 99.99%
- Baixa lat√™ncia e alta taxa de transfer√™ncia
- Projetado para acesso frequente
- Toler√¢ncia a falhas em at√© duas zonas de disponibilidade
- Casos de uso:
    - Big data analytics
    - Aplica√ß√µes e jogos online
    - Distribui√ß√£o de conte√∫do

---

### S3 Standard ‚Äì Infrequent Access (IA)
- Ideal para dados acessados esporadicamente, mas que requerem recupera√ß√£o r√°pida
- Custo reduzido de armazenamento
- Cobran√ßa por recupera√ß√£o de dados
- 99.9% de disponibilidade
- Casos de uso:
    - Backups
    - Recupera√ß√£o de desastres

---

### S3 One Zone ‚Äì Infrequent Access (One Zone-IA)
- Armazenamento em apenas uma zona de disponibilidade
- Durabilidade igual (11 9's), mas risco maior em caso de falha da AZ
- 99.5% de disponibilidade
- Casos de uso:
    - Backups secund√°rios
    - Dados tempor√°rios ou que podem ser recriados


---

### S3 Glacier

Classe de armazenamento para arquivamento de longo prazo com custo muito baixo. Acesso eventual e controlado.
#### S3 Glacier Instant Retrieval
- Recupera√ß√£o em milissegundos
- Armazenamento m√≠nimo: 90 dias
- Ideal para arquivos arquivados com necessidade ocasional de acesso imediato
- Casos de uso:
    - Backups trimestrais
    - Arquivos de auditoria

#### S3 Glacier Flexible Retrieval
- Tr√™s modos de recupera√ß√£o:
    - Expedited: 1 a 5 minutos
    - Standard: 3 a 5 horas
    - Bulk: 5 a 12 horas (mais econ√¥mico)
- Armazenamento m√≠nimo: 90 dias
- Casos de uso:
    - Arquivamento de grandes volumes com acesso espor√°dico
#### S3 Glacier Deep Archive
- Custo mais baixo entre todas as classes
- Armazenamento m√≠nimo: 180 dias
- Modos de recupera√ß√£o:
    - Standard: 12 horas
    - Bulk: 48 horas
- Casos de uso:
    - Arquivamento de longo prazo (documentos fiscais, jur√≠dicos, hist√≥ricos)

---

### S3 Intelligent-Tiering
- Gerencia automaticamente o n√≠vel de armazenamento com base no padr√£o de acesso
- N√£o h√° cobran√ßa por recupera√ß√£o
- Cobran√ßa por monitoramento mensal (baixo custo)
- Ideal para dados com padr√µes de acesso imprevis√≠veis

#### Camadas de acesso

| Camada                 | Crit√©rio de movimenta√ß√£o   | Tipo       |
| ---------------------- | -------------------------- | ---------- |
| Frequent Access        | Acesso constante           | Autom√°tica |
| Infrequent Access      | 30 dias sem acesso         | Autom√°tica |
| Archive Instant Access | 90 dias sem acesso         | Autom√°tica |
| Archive Access         | 90 a 700+ dias sem acesso  | Opcional   |
| Deep Archive Access    | 180 a 700+ dias sem acesso | Opcional   |

### S3 Express One Zone

O **Amazon S3 Express One Zone** √© uma nova classe de armazenamento projetada para **workloads de alto desempenho e grande volume de dados**, que exigem **acesso r√°pido e frequente aos objetos**. Diferente de outras classes do S3 que replicam dados entre m√∫ltiplas Zonas de Disponibilidade (AZs), o S3 Express One Zone **armazena os dados em uma √∫nica AZ**, oferecendo **lat√™ncia sub-milissegundo** e **alta taxa de IOPS**, com um custo mais baixo.

---

#### Caracter√≠sticas Principais
- **Armazenamento em uma √∫nica AZ**: Ideal para dados **tempor√°rios**, **n√£o cr√≠ticos** ou que podem ser **reproduzidos**, onde a durabilidade entre m√∫ltiplas zonas n√£o √© essencial.
- **Alta taxa de transfer√™ncia e baixa lat√™ncia**: Otimizado para **opera√ß√µes frequentes de leitura/grava√ß√£o** em objetos de tamanho pequeno a m√©dio.
- **Namespace compat√≠vel com POSIX**: Permite **consist√™ncia forte de leitura ap√≥s escrita** e **acesso paralelo eficiente**.
- **Custo-benef√≠cio**: Mais econ√¥mico que o S3 Standard Multi-AZ, especialmente em casos de uso com alto volume e sens√≠veis √† performance.

---

#### Aplica√ß√µes em Engenharia de Dados

O S3 Express One Zone √© especialmente √∫til em pipelines de engenharia de dados que exigem **performance e escalabilidade**:
- **ETL Staging**: Armazenamento tempor√°rio para transforma√ß√£o de dados antes de transferir para S3 Standard ou Redshift.
- **Ingest√£o de Streams**: Buffer para ingest√£o de dados de alto volume vindos do Amazon Kinesis ou Apache Kafka.
- **Feature Store de Machine Learning**: Acesso r√°pido a vetores de caracter√≠sticas (features) para infer√™ncia em tempo real.
- **Espa√ßo Tempor√°rio (scratch space)**: Armazenamento intermedi√°rio de alta velocidade para jobs do Spark (Amazon EMR ou AWS Glue).

---

#### Quando Utilizar

- Voc√™ precisa de acesso em **escala de milissegundos** a objetos acessados com frequ√™ncia.
- Pode tolerar a **durabilidade de uma √∫nica AZ** (ou os dados podem ser recuperados da fonte).
- Deseja **alto desempenho com custo reduzido** para dados de curta dura√ß√£o.

---

#### Considera√ß√µes

- **N√£o √© indicado para dados cr√≠ticos ou de arquivamento**, devido √† aus√™ncia de redund√¢ncia entre zonas.
- Dispon√≠vel **apenas em algumas regi√µes e zonas espec√≠ficas da AWS**.
- **Durabilidade menor**: 99.99%, comparado a 11 9‚Äôs das classes multi-AZ.

---
#### Conclus√£o

O **S3 Express One Zone** preenche uma lacuna importante em workflows modernos de engenharia de dados ao oferecer um armazenamento **r√°pido, simples e econ√¥mico**. Ele permite **ETLs mais responsivos**, **pipelines de treinamento mais √°geis** e **an√°lises em tempo real**, com um custo menor que o armazenamento tradicional.

---
### Considera√ß√µes Finais
- √â poss√≠vel configurar **lifecycle rules** para automatizar a transi√ß√£o entre classes com base no tempo de inatividade.
- Escolher a classe adequada pode reduzir custos de forma significativa sem comprometer durabilidade ou seguran√ßa.
### Compara√ß√µes
![[Pasted image 20250728182441.png]]
![[Pasted image 20250728182455.png]]

## S3 - Regras de Ciclo de Vida (Lifecycle)

As **Lifecycle Rules** do Amazon S3 permitem **automatizar o gerenciamento de objetos**, movendo-os entre classes de armazenamento ou deletando-os com base em regras definidas por tempo.

---
### üì¶ Objetivo

Reduzir custos ao mover objetos para **classes de armazenamento mais baratas** de acordo com a frequ√™ncia de acesso e o tempo de vida √∫til.

---
### üå± Regras de Lifecycle

#### üîÅ A√ß√µes de Transi√ß√£o (Transition Actions)

Movem automaticamente os objetos entre classes de armazenamento.
Exemplos:
- Mover objetos para **Standard-IA** ap√≥s 60 dias da cria√ß√£o.
- Mover objetos para **Glacier** ap√≥s 180 dias para arquivamento de longo prazo.
#### ‚õî A√ß√µes de Expira√ß√£o (Expiration Actions)
Dele√ß√£o autom√°tica de objetos que n√£o s√£o mais necess√°rios.
Exemplos:
- Deletar logs de acesso ap√≥s 365 dias.
- Deletar vers√µes antigas de arquivos (se o versionamento estiver habilitado).
- Deletar partes de upload **incompleto** de objetos Multipart ap√≥s um per√≠odo.
#### üîÄ Aplica√ß√£o das regras
Regras de ciclo de vida podem ser aplicadas por:
- **Prefixo**: `s3://meubucket/mp3/*`
- **Tags**: exemplo, `{"departamento": "financeiro"}`

---

### üìò Cen√°rios de Exemplo

#### üì∑ Cen√°rio 1: Miniaturas de imagens

> Seu aplicativo no EC2 cria **miniaturas** de imagens ap√≥s o upload dos perfis no S3.  
> Essas miniaturas **podem ser recriadas facilmente** e devem ser mantidas por **apenas 60 dias**.  
> As imagens de origem devem ter **acesso imediato** por 60 dias e, depois disso, **podem ser acessadas em at√© 6 horas**.

**Solu√ß√£o:**
- Armazene as imagens de origem no **S3 Standard**.
    - Configure Lifecycle para mover para **S3 Glacier Flexible Retrieval** ap√≥s 60 dias.
- Armazene as miniaturas no **S3 One Zone-IA**.
    - Configure Lifecycle para **expirar** os objetos ap√≥s 60 dias.
---

#### üóÉÔ∏è Cen√°rio 2: Recupera√ß√£o de objetos exclu√≠dos

> Sua empresa exige que objetos exclu√≠dos possam ser **recuperados imediatamente por at√© 30 dias**.  
> Ap√≥s isso, devem permanecer acess√≠veis dentro de **48 horas**, por at√© 1 ano.
**Solu√ß√£o:**
- **Habilite o versionamento no bucket**. Isso garante que a exclus√£o l√≥gica s√≥ aplique um **delete marker**, preservando vers√µes anteriores.
- Configure Lifecycle para mover **vers√µes n√£o atuais** para:
    - **S3 Standard-IA** ap√≥s 30 dias.
    - **S3 Glacier Deep Archive** ap√≥s 365 dias.
---
### üìä S3 Analytics

Servi√ßo complementar que ajuda a tomar decis√µes baseadas em dados sobre ciclo de vida e classes de armazenamento.
**Caracter√≠sticas:**
- **Recomenda√ß√µes autom√°ticas** para mover objetos da classe Standard para **Standard-IA**.
- **N√£o recomenda** migra√ß√£o para **One Zone-IA** ou **Glacier**.
- Relat√≥rios atualizados **diariamente**.
- Pode levar **24 a 48 horas** para que as an√°lises comecem.
- Ideal para **otimizar e ajustar** regras de Lifecycle existentes.
## S3 ‚Äì Event Notifications

O recurso **S3 Event Notifications** permite receber notifica√ß√µes quando determinados eventos ocorrem em um bucket do Amazon S3, como:
- `s3:ObjectCreated`
- `s3:ObjectRemoved`
- `s3:ObjectRestore`
- `s3:Replication`

Esses eventos podem ser enviados para servi√ßos como **Amazon SNS**, **Amazon SQS**, **AWS Lambda**, entre outros.  
A notifica√ß√£o pode levar alguns segundos ou minutos para ser entregue.

---
### Configura√ß√£o
- N√£o utiliza **fun√ß√µes IAM** diretamente para o S3.
- √â necess√°rio configurar **pol√≠ticas de acesso a recurso** no destino (SNS, SQS, Lambda) para permitir que o S3 envie notifica√ß√µes.
- Exemplo: no SNS, criar e anexar uma **resource policy** permitindo que o bucket envie mensagens para o t√≥pico.
![[Pasted image 20250729165550.png]]
---
### Exemplo de Uso

- Filtrar eventos para objetos que terminam com `.jpg`.
- Caso de uso: gerar miniaturas automaticamente de imagens carregadas no S3.
    - Criar uma **Event Notification** no bucket.
    - Definir o evento `s3:ObjectCreated` com filtro `.jpg`.
    - Enviar para um destino, como uma fun√ß√£o **AWS Lambda** que processa as imagens.
---
## S3 Event Notifications com EventBridge

O **Amazon EventBridge** oferece uma integra√ß√£o mais avan√ßada para eventos do S3.
- √â poss√≠vel configurar para que **todos os eventos do bucket** sejam enviados para o EventBridge.
- Dentro do EventBridge, podem ser criadas **regras** para direcionar eventos para **diversos destinos** (at√© 18 tipos diferentes de servi√ßos).
---
### Melhorias do EventBridge sobre Event Notifications

- **Filtragem avan√ßada** com JSON rules (ex.: metadados, tamanho do objeto, nome do arquivo).
- **M√∫ltiplos destinos**: Step Functions, Kinesis Data Streams, Kinesis Data Firehose, etc.
- **Recursos adicionais**:
    - Arquivamento de eventos
    - Reprodu√ß√£o de eventos
    - Entrega mais confi√°vel (**Reliable Delivery**)

---
## S3 ‚Äì Baseline Performance

- O Amazon S3 √© **automaticamente escal√°vel** para um n√∫mero muito alto de solicita√ß√µes, com **lat√™ncia t√≠pica de 100‚Äì200 ms**.
- Por **prefixo** no bucket, uma aplica√ß√£o pode realizar:
    - **3.500** opera√ß√µes `PUT` / `COPY` / `POST` / `DELETE` por segundo
    - **5.500** opera√ß√µes `GET` / `HEAD` por segundo
- **N√£o h√° limite** para a quantidade de prefixos em um bucket.
### Exemplo de Prefixos

Um **prefixo** √© definido pelo caminho at√© antes do nome do arquivo.  
Exemplo de caminhos de objetos e seus prefixos:

| Caminho do Objeto          | Prefixo          |
| -------------------------- | ---------------- |
| `bucket/folder1/sub1/file` | `/folder1/sub1/` |
| `bucket/folder1/sub2/file` | `/folder1/sub2/` |
| `bucket/folder1/sub3/file` | `/folder1/sub3/` |
| `bucket/folder1/sub4/file` | `/folder1/sub4/` |

**C√°lculo de throughput:**  
Se cada prefixo pode ter at√© 5.500 GETs/s, com 4 prefixos diferentes √© poss√≠vel atingir **22.000 GETs/s** no total.

---
## S3 ‚Äì Performance Features
### Multi-Part Upload
- Recomendado para arquivos **acima de 100 MB**.
- **Obrigat√≥rio** para arquivos **acima de 5 GB**.
- Divide o arquivo em partes menores e realiza o upload **em paralelo** para aumentar a velocidade.
- Melhora a resili√™ncia: partes com falha podem ser reenviadas sem reiniciar o upload inteiro.
---
### S3 Transfer Acceleration

- Aumenta a velocidade de upload enviando arquivos para um **AWS Edge Location** pr√≥ximo ao cliente.
- O Edge encaminha o arquivo pela **rede otimizada da AWS** at√© o bucket S3 na regi√£o de destino.
- Compat√≠vel com **Multi-Part Upload**.
- Ideal para uploads a partir de localiza√ß√µes geograficamente distantes da regi√£o do bucket.
![[Pasted image 20250729174634.png]]
---
## S3 ‚Äì Byte-Range Fetches

- Permite baixar **intervalos espec√≠ficos de bytes** de um objeto.
- Vantagens:
    - **Paraleliza downloads** dividindo o arquivo em N partes e baixando todas em paralelo.
    - **Resili√™ncia**: se uma parte falhar, apenas aquela parte √© solicitada novamente.
    - Pode ser usado para **recuperar apenas uma parte** espec√≠fica do arquivo (ex.: cabe√ßalho de um v√≠deo).
- √ötil para **acelerar downloads** e otimizar consumo de rede.
 ![[Pasted image 20250729174605.png]]

## S3 - Object Encryption
Existem 4 metodos de criptografia de arquivos para o S3 

### Server-Side Encryption (SSE)
#### SSE com S3-Managed Keys (SSE-3) Default
* Criptografa os objetos da S3 usando uma chave que √© manipulada, gerenciada e de propriedade da AWS. (N√£o temos acesso a essa key)
* O objeto √© criptografado pelo server da AWS (server-side)
* Criptografado com [AES-256](https://pt.wikipedia.org/wiki/Advanced_Encryption_Standard)
* Para que o objeto seja criptografado deve ser definido o cabe√ßalho `x-amz-server-side-encryption": "AES256"` para que o S3 criptografe o objeto
* Ativo por padr√£o em novos buckets e novos objetos
![[Pasted image 20250730172111.png]]
---
#### SSE com KMS armazenadas no AWS KMS (SSE-KMS)
* Aproveita o AWS Key Management Service ([AWS KMS](obsidian://open?vault=estudos_aws_data_engenier&file=AWS-Data-Engineer-Certificacao%2FSecurity-Identity-And-Compliance%2FAWS%20Key%20Management%20Service%20(AWS%20KMS))) para gerenciar chaves de criptografia
* Vantagens do KMS: controle do usu√°rio + uso da chave de auditoria usando [CloudTrail](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-user-guide.html)
* Objeto √© criptografado no lado do servidor
* Para que o objeto seja criptografado deve ser definido o cabe√ßalho `"x-amz-server-side-encryption": "aws:kms"`
![[Pasted image 20250730172256.png]]
##### Limita√ß√µes do SSE-KMS 
- Opera√ß√µes contam para o limite de requisi√ß√µes do KMS:
    - **Upload**: chama `GenerateDataKey` na API do KMS.
    - **Download**: chama `Decrypt` na API do KMS.
- Limite padr√£o: **5.500 / 10.000 / 30.000 req/s** (dependendo da regi√£o).
- √â poss√≠vel solicitar aumento via **Service Quotas Console**.
![[Pasted image 20250730172536.png]]
---
#### DSSE-KMS
- "Dual-Layer Server-Side Encryption" com chaves no KMS.
- Aplica **duas camadas de criptografia independentes** para maior seguran√ßa.
---
#### SSE com Customer-provided Keys (SSE-C)
* Cliente **gera e gerencia suas pr√≥prias chaves**.
- Criptografia feita pelo servidor S3, mas **a chave nunca √© armazenada pela AWS**.
- Requisitos:
    - Conex√£o **HTTPS obrigat√≥ria**.
    - Chave fornecida nos cabe√ßalhos HTTP **em cada requisi√ß√£o**.
- √ötil para compliance onde as chaves n√£o podem ser armazenadas na nuvem.
![[Pasted image 20250730172751.png]]
---
### Client-Side Encryption (O cliente criptografa)
- O cliente **criptografa localmente** antes de enviar ao S3.
- Descriptografia tamb√©m √© feita localmente.
- O cliente gerencia **totalmente** as chaves.
- Pode ser implementada com bibliotecas como a **Amazon S3 Encryption Client Library**.
![[Pasted image 20250730173018.png]]
Para o exame, √© importante entender quais s√£o utlizadas para cada situa√ß√£o

----
### S3 - Encryption in transit (SSL/TLS)
- Protege os dados **em tr√¢nsito** entre cliente e S3.
- S3 possui dois endpoints:
    - `HTTP` ‚Äì **n√£o criptografado**.
    - `HTTPS` ‚Äì **criptografado** com SSL/TLS.
- **HTTPS √© recomendado** (e obrigat√≥rio para SSE-C).
- √â poss√≠vel **for√ßar** que uploads/downloads usem apenas HTTPS.
* Como for√ßar a criptografia em transito (SSL/TLS):
![[Pasted image 20250730174441.png]]

## S3 - Criptografia padr√£o vs Politicas de bucket
- A criptografia **SSE-S3** pode ser aplicada **automaticamente** a todos os novos objetos armazenados no bucket (**Default Encryption**).
- Opcionalmente, √© poss√≠vel **for√ßar o uso de criptografia** criando uma **pol√≠tica de bucket** que:
    - Recusa chamadas de API `PUT` para o S3 **sem criptografia**.
    - Pode exigir tipos espec√≠ficos de criptografia, como **SSE-KMS** ou **SSE-C**.
- **Nota:** As **pol√≠ticas de bucket** s√£o avaliadas **antes** da configura√ß√£o de **Default Encryption**.  
    Ou seja, se a pol√≠tica bloquear um upload sem criptografia, ele ser√° rejeitado **antes** que o S3 aplique a criptografia padr√£o.
- Exemplo:
```json
{
  "Version": "2012-10-17",
  "Id": "ForceS3Encryption",
  "Statement": [
    {
      "Sid": "DenyUnEncryptedObjectUploads",
      "Effect": "Deny",
      "Principal": "*",
      "Action": "s3:PutObject",
      "Resource": "arn:aws:s3:::NOME_DO_BUCKET/*",
      "Condition": {
        "StringNotEqualsIfExists": {
          "s3:x-amz-server-side-encryption": [
            "AES256",
            "aws:kms"
          ]
        }
      }
    }
  ]
}
```

## S3- Access Points
O **Amazon S3 Access Points** simplifica o gerenciamento de **acesso e seguran√ßa** para buckets S3, especialmente em ambientes com m√∫ltiplos aplicativos ou equipes acessando os mesmos dados.
- Cada **Access Point** possui:
    - **Nome DNS exclusivo**:
        - **Internet Origin**: acess√≠vel publicamente (seguindo pol√≠ticas definidas).
        - **VPC Origin**: acess√≠vel apenas a partir de uma VPC.
    - **Pol√≠tica pr√≥pria** (_Access Point Policy_), semelhante √† **Bucket Policy**, mas aplicada **somente aos acessos via aquele ponto**.
- Permite aplicar **regras de seguran√ßa espec√≠ficas** por aplica√ß√£o ou equipe, sem alterar a pol√≠tica global do bucket.
- Facilita **gerenciamento em escala** para grandes ambientes com diversos consumidores de dados.
![[Pasted image 20250730200104.png]]
### VPC Origin
- Configura o Access Point para ser **acess√≠vel apenas de dentro de uma VPC**.
- Necess√°rio criar um **VPC Endpoint** (Gateway ou Interface) para acessar o ponto.
- A **VPC Endpoint Policy** deve permitir acesso tanto:
    - Ao **bucket alvo**.
    - Ao **Access Point**.
- Garantia de **isolamento de tr√°fego** ‚Äî dados nunca saem da rede privada da AWS.
### Quando usar Access Points
- Diferentes **times** ou **aplica√ß√µes** precisam de acesso a diferentes partes do bucket.
- Necessidade de **isolar tr√°fego privado** de uma VPC para o S3.
- Aplicar **pol√≠ticas de acesso espec√≠ficas** sem impactar o acesso geral ao bucket.
![[Pasted image 20250730200219.png]]

## S3 Object Lambda

###  Como funciona
1. Voc√™ possui **apenas um bucket S3** contendo os objetos originais.
2. Cria um **S3 Access Point** normal.
3. Configura um **S3 Object Lambda Access Point**, vinculado ao Access Point original.
4. Associa uma **fun√ß√£o AWS Lambda** para processar o objeto **antes** de retorn√°-lo ao cliente.

---
###  Casos de uso
- **Anonimiza√ß√£o de dados sens√≠veis**  
    Ex.: Remover informa√ß√µes pessoais (PII) para ambientes anal√≠ticos ou n√£o produtivos.
- **Convers√£o de formatos**  
    Ex.: Transformar XML em JSON no momento da leitura.
- **Processamento de imagens em tempo real**  
    Ex.: Redimensionamento e adi√ß√£o de marca d‚Äô√°gua espec√≠fica para o usu√°rio que fez a solicita√ß√£o.
- **Filtragem de dados**  
    Ex.: Retornar apenas colunas ou linhas relevantes de um CSV grande.

---
### Benef√≠cios
- Elimina a necessidade de manter v√°rias c√≥pias de objetos processados.
- Aplica transforma√ß√µes **sob demanda**.
- Reduz custos de armazenamento.
- Permite **personaliza√ß√£o por usu√°rio** no momento da leitura.
- **O S3 Object Lambda n√£o cria nem armazena uma nova c√≥pia no bucket S3.**
![[Pasted image 20250731184442.png]]
# S3 ‚Äì Storage Lens

O **Amazon S3 Storage Lens** fornece **visibilidade centralizada** para analisar, compreender e otimizar o uso do armazenamento em toda uma **conta** ou **organiza√ß√£o AWS**.

---
## üîπ Principais Recursos
- Analisar e otimizar o **armazenamento** em toda a organiza√ß√£o AWS.
- Detectar **anomalias**, identificar **oportunidades de economia** e melhorar pr√°ticas de **prote√ß√£o de dados**.
- M√©tricas de uso e atividade para at√© **30 dias**.
- Dados podem ser agregados por:
  - Organiza√ß√£o
  - Conta espec√≠fica
  - Regi√£o
  - Bucket
  - Prefixo
- Possibilidade de exportar m√©tricas **diariamente** para um bucket S3 (CSV ou Parquet).
- Dispon√≠vel via **painel padr√£o** ou **pain√©is personalizados**.

---
## Storage Lens ‚Äì Default Dashboard
- Pr√©-configurado pelo Amazon S3.
- Exibe dados **multi-regi√£o** e **multi-conta**.
- N√£o pode ser exclu√≠do, mas pode ser **desativado**.
- Gratuito (com m√©tricas padr√£o).

---
## Storage Lens ‚Äì Tipos de M√©tricas

### **1. Summary Metrics**
- Informa√ß√µes gerais sobre armazenamento.
- Exemplos: `StorageBytes`, `ObjectCount`.
- Uso: identificar buckets/prefixos de crescimento r√°pido ou n√£o utilizados.

---
### **2. Cost-Optimization Metrics**
- Insights para **reduzir custos de armazenamento**.
- Exemplos: `NonCurrentVersionStorageBytes`, `IncompleteMultipartUploadStorageBytes`.
- Uso:
  - Encontrar uploads multipart incompletos.
  - Identificar objetos para mover para classes de armazenamento mais baratas.

---
### **3. Data-Protection Metrics**
- Avalia recursos de **prote√ß√£o de dados**.
- Exemplos: `VersioningEnabledBucketCount`, `MFADeleteEnabledBucketCount`, `SSEKMSEnabledBucketCount`, `CrossRegionReplicationRuleCount`.
- Uso: encontrar buckets que n√£o seguem as melhores pr√°ticas de seguran√ßa.

---
### **4. Access-Management Metrics**
- Analisa **propriedade de objetos** e controle de acesso.
- Exemplo: `BucketOwnerEnforcedBucketCount`.
- Uso: verificar configura√ß√µes de propriedade de objetos.

---
### **5. Event Metrics**
- Mostra quais buckets possuem **notifica√ß√µes de eventos S3** habilitadas.
- Exemplo: `EventNotificationEnabledBucketCount`.

---
### **6. Performance Metrics**
- Identifica buckets com **Transfer Acceleration** ativado.
- Exemplo: `TransferAccelerationEnabledBucketCount`.

---
### **7. Activity Metrics**
- Mede como o armazenamento √© acessado.
- Exemplos: `GetRequests`, `PutRequests`, `ListRequests`, `BytesDownloaded`.

---
### **8. Detailed Status Code Metrics**
- Analisa **c√≥digos HTTP** retornados pelo S3.
- Exemplos: `200OKStatusCount`, `403ForbiddenErrorCount`, `404NotFoundErrorCount`.

---
## Free vs Paid

| Categoria | Gratuito | Avan√ßado (Pago) |
|-----------|----------|-----------------|
| N¬∫ de m√©tricas | ~28 m√©tricas b√°sicas | M√©tricas extras + recomenda√ß√µes |
| Reten√ß√£o | 14 dias | 15 meses |
| Tipos de m√©tricas | Uso e atividade b√°sicas | Otimiza√ß√£o de custo, prote√ß√£o de dados, c√≥digos de status detalhados |
| Exporta√ß√£o para CloudWatch | N√£o incluso | Incluso |
| Agrega√ß√£o por prefixo | N√£o | Sim |
#### IMPORTANTE , TESTAR PARA ENTENDER COMO FUNCIONA
![[Pasted image 20250731191714.png]]
## Referencia
[Conteudo S3 AWS](https://aws.amazon.com/pt/s3/)
[AWS Glacier](https://aws.amazon.com/pt/s3/storage-classes/glacier/)
[Categorias de armazenamento do Amazon S3](https://aws.amazon.com/pt/s3/storage-classes/)
[Replicate](https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication.html)
   