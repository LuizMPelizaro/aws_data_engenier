# Amazon Redshift
#tema/analytics
#tema/database 

##  O que √© o Redshift
- **Data Warehouse totalmente gerenciado** da AWS.
- Escala de **terabytes a petabytes**.
	- **Extremamente dimension√°vel e r√°pido** ‚Üí Redshift permite escalar armazenamento e computa√ß√£o de forma independente (especialmente com RA3 e Serverless), mantendo performance mesmo em cargas muito grandes.
	- **Utiliza Machine Learning** ‚Üí para otimizar execu√ß√£o de queries, prever tempo de consultas curtas (SQA), ajustar automaticamente o Workload Management e at√© otimizar cache e planos de execu√ß√£o.
	- **Executa consultas massivamente paralelas (MPP)** ‚Üí o processamento √© distribu√≠do entre m√∫ltiplos n√≥s em paralelo, acelerando an√°lises em petabytes de dados.
- Focado em [**OLAP (Online Analytical Processing)**](obsidian://open?vault=aws_data_engenier&file=AWS-Data-Engineer-Certificacao%2FData-Engineering-Fundamentals%2FOLAP%20VS%20OLTP), n√£o em OLTP (transa√ß√µes).
- Permite consultas r√°pidas em grandes volumes de dados usando **SQL padr√£o**, com suporte a **ODBC/JDBC**.
- Integra-se nativamente com o ecossistema AWS (S3, Glue, Athena, QuickSight).
- **Custo-efetivo**: paga-se pelos n√≥s e pelo armazenamento, com possibilidade de **pausar e retomar clusters**.
- Utiliza o modo colunar de trabalhar OLAP
---
## MPP
**MPP (Massively Parallel Processing)** √© um modelo de processamento de dados onde uma consulta ou tarefa √© **dividida em partes menores** e distribu√≠da entre **m√∫ltiplos n√≥s (m√°quinas)** que trabalham **em paralelo**.

‚û°Ô∏è No contexto de data warehouses como o Amazon Redshift:
- Cada **n√≥** do cluster processa uma parte dos dados.
- O **l√≠der (leader node)** coordena, divide a query e depois agrega os resultados parciais.
- Isso permite que consultas que levariam horas em um √∫nico servidor sejam resolvidas em **segundos ou minutos**.

üîë Caracter√≠sticas do MPP:
- **Escalabilidade horizontal** ‚Üí basta adicionar n√≥s ao cluster para processar mais dados.
- **Alta performance** ‚Üí aproveita processamento paralelo de CPU, mem√≥ria e I/O.
- **Ideal para OLAP** (consultas anal√≠ticas complexas sobre grandes volumes de dados).

üëâ Exemplo simples:  
Imagine consultar 1 PB de dados.
- Em um servidor √∫nico (processamento serial), ele teria que ler tudo sozinho.
- Em um cluster MPP com 100 n√≥s, cada n√≥ processa **1% dos dados em paralelo**, e o leader node junta os resultados finais.
---
##  Como entrega performance
- **MPP (Massively Parallel Processing)**: divide consultas em m√∫ltiplos n√≥s que processam em paralelo.
- **Armazenamento colunar**: otimizado para consultas anal√≠ticas (scans, agrega√ß√µes).
- **Compress√£o de colunas**: reduz espa√ßo e acelera leitura.
- **Machine Learning (Auto-tuning)**: Redshift usa ML para ajustar planos de execu√ß√£o e caching.
---
##  Casos de uso comuns
- **Moderniza√ß√£o de data warehouse** legados (substitui Oracle/Teradata, etc.).
- **An√°lises globais de vendas**.
- **Dados hist√≥ricos de mercado financeiro** (ex.: negocia√ß√µes de a√ß√µes).
- **Publicidade digital**: an√°lise de impress√µes, cliques, convers√µes.
- **Gaming analytics**: agrega√ß√£o de eventos e m√©tricas de jogadores.
- **An√°lise de tend√™ncias sociais**.
- **Unifica√ß√£o de Data Warehouse + Data Lake** (Redshift + Spectrum + S3).
## Arquitetura do Amazon Redshift 
![[Pasted image 20250910183954.png]]
### 1. **Cluster**
- Unidade principal de infraestrutura do Redshift.
- Cont√©m **um n√≥ l√≠der** e **1 a 128 n√≥s de computa√ß√£o** (dependendo do tipo/ra3, dc2, etc.).
- Pode hospedar **um ou mais bancos de dados**.
- √â a camada **vis√≠vel para o usu√°rio**: voc√™ se conecta ao cluster e n√£o diretamente aos n√≥s.
---
### 2. **N√≥ L√≠der (Leader Node)**
- Atua como **controlador e coordenador**.
- Fun√ß√µes principais:
    1. Receber consultas dos clientes (via JDBC/ODBC, API, console, etc.).
    2. **Analisar e gerar o plano de execu√ß√£o** (query execution plan).
    3. Distribuir etapas do plano para os **n√≥s de computa√ß√£o**.
    4. Agregar resultados intermedi√°rios e retornar ao cliente.
- N√£o armazena dados do usu√°rio (apenas metadados e cat√°logo do sistema).
- √â um **ponto √∫nico de entrada** para o cluster.
---
### 3. **N√≥s de Computa√ß√£o (Compute Nodes)**
- Onde os **dados do usu√°rio s√£o realmente armazenados**.
- Cada n√≥ tem:
    - **CPU dedicada**
    - **Mem√≥ria**
    - **Armazenamento em disco**
- Fun√ß√µes:
    - Executar etapas do plano de execu√ß√£o enviadas pelo n√≥ l√≠der.
    - Trocar dados entre si (quando necess√°rio, ex: joins entre tabelas).
    - Enviar resultados intermedi√°rios de volta ao n√≥ l√≠der.

---
### 4. **Fatias (Slices)**
- Cada n√≥ de computa√ß√£o √© dividido em **fatias**.
- Cada fatia recebe **uma por√ß√£o dos dados** e da carga de trabalho.
- O n√∫mero de fatias depende do tipo de n√≥ (ex.: um n√≥ `ra3.16xlarge` tem muito mais fatias do que um `ra3.4xlarge`).
- **Processamento paralelo real** ‚Üí cada fatia executa parte da query sobre seu peda√ßo de dados.
üìå Exemplo:
- Um cluster com **4 n√≥s de computa√ß√£o**.
- Cada n√≥ √© dividido em **8 fatias**.
- Total: **32 fatias trabalhando em paralelo**, cada uma processando parte da tabela.
---
## Como o fluxo funciona
1. Cliente envia uma query (SQL).
2. O **n√≥ l√≠der**:
    - Analisa a query.
    - Cria o plano de execu√ß√£o.
    - Distribui tarefas para cada fatia nos n√≥s de computa√ß√£o.
3. **Fatias** processam os dados localmente em paralelo.
4. Resultados intermedi√°rios s√£o enviados de volta ao **n√≥ l√≠der**.
5. O n√≥ l√≠der agrega e retorna o resultado final ao cliente.
---
##  Por que isso √© importante?
- **MPP (Massively Parallel Processing)** √© implementado justamente por essa divis√£o em n√≥s e fatias.
- Essa arquitetura garante:
    - Escalabilidade ‚Üí adiciona n√≥s = mais fatias = mais paralelismo.
    - Performance ‚Üí processamento distribu√≠do.
    - Flexibilidade ‚Üí voc√™ escolhe o tipo e tamanho dos n√≥s conforme custo/performance desejados.
---
üëâ Resumindo:
- **Cluster** = cont√™iner geral.
- **Leader Node** = c√©rebro (planejamento + coordena√ß√£o).
- **Compute Nodes** = m√∫sculos (armazenamento + execu√ß√£o).
- **Slices** = subdivis√µes dentro dos m√∫sculos (paralelismo real).

---
## Redshift Spectrum
- Permite **consultar dados diretamente no S3**, sem precisar carreg√°-los para o cluster.
- Suporta **exabytes de dados n√£o estruturados ou semiestruturados** (CSV, Parquet, JSON, etc.).
- **Escalabilidade horizontal**: processa consultas em paralelo em centenas de n√≥s ‚ÄúSpectrum‚Äù.
- Separa **compute** (Redshift cluster) de **storage** (S3).
- Suporte a **compress√£o Gzip/Snappy**.
---
## Durabilidade e disponibilidade
- **Replica√ß√£o dentro do cluster** (n√≥s de dados replicados).
- **Backups autom√°ticos no S3**.
- **Snapshots ass√≠ncronos replicados para outra regi√£o** (DR).
- **Troca autom√°tica de discos/n√≥s com falha**.
- Antes: cluster limitado a **1 zona de disponibilidade (AZ)**.
- Agora: **Multi-AZ dispon√≠vel para n√≥s RA3** ‚Üí mais resili√™ncia e HA.
---
## Escalabilidade no Redshift
- **Escala vertical e horizontal sob demanda**.
- Durante scaling:
    - Novo cluster √© criado em paralelo.
    - Cluster antigo **ainda pode ser lido**.
    - Quando pronto, o **CNAME √© trocado** para o novo cluster.
    - Pode haver **alguns minutos de downtime** no redirecionamento.
    - Dados s√£o movidos em paralelo para os novos n√≥s de compute.
---
## Distribution Styles (como os dados s√£o distribu√≠dos entre n√≥s)
- **AUTO**: Redshift decide com base no tamanho da tabela.
- **EVEN**: distribui√ß√£o round-robin das linhas entre slices.
- **KEY**: linhas s√£o distribu√≠das com base em uma coluna (ideal para joins).
- **ALL**: a tabela inteira √© replicada em todos os n√≥s (bom para tabelas pequenas e lookup tables).

üí° Escolher bem o distribution style √© **cr√≠tico para performance** ‚Äî minimiza data shuffling entre n√≥s durante joins.

---
![[Pasted image 20250910184559.png]]
![[Pasted image 20250910184614.png]]
![[Pasted image 20250910184622.png]]
---
## Importa√ß√£o e Exporta√ß√£o de dados
- **COPY (importa√ß√£o)**
    - Carrega dados de forma **paralelizada e eficiente**.
    - Suporta fontes: **S3, EMR, DynamoDB, hosts remotos**.
    - S3 exige manifest file + IAM role.
    - Pode **descriptografar** dados durante o load.
    - Suporta **compress√£o (gzip, lzop, bzip2)**.
    - Usa **SSL com acelera√ß√£o por hardware**.
    - Pode aplicar **compress√£o autom√°tica** com base no perfil do dataset.
    - Melhor pr√°tica: carregar **narrow tables (muitas linhas, poucas colunas)** em uma √∫nica transa√ß√£o COPY.
- **UNLOAD (exporta√ß√£o)**
    - Exporta dados do Redshift para arquivos no **S3**.
    - Gera arquivos em paralelo, de acordo com os n√≥s do cluster.
- **Integra√ß√µes recentes**
    - **Enhanced VPC Routing**: tr√°fego for√ßado pela VPC para maior controle.
    - **Auto-copy do S3**: integra√ß√£o automatizada.
    - **Aurora zero-ETL**: integra√ß√£o nativa Aurora ‚Üí Redshift.
    - **Streaming ingestion**: ingest√£o direta de streams do **Kinesis Data Streams** ou **MSK (Kafka)**.
---
## Cross-region Snapshot Copy (para DR e backup)
Quando o cluster √© criptografado com KMS:
1. **Na regi√£o de destino**:
    - Criar chave KMS.
    - Criar um **snapshot copy grant** ligado a essa chave.
2. **Na regi√£o de origem**:
    - Ativar c√≥pia de snapshots para o copy grant criado.
‚û°Ô∏è Assim, snapshots s√£o replicados entre regi√µes de forma segura.
---

## üîπ DBLINK e integra√ß√£o com PostgreSQL

Como Redshift √© baseado em PostgreSQL, √© poss√≠vel usar **dblink / postgres_fdw** para integrar e sincronizar dados:

``` SQL
CREATE EXTENSION postgres_fdw; 
CREATE EXTENSION dblink;  

CREATE SERVER foreign_server FOREIGN DATA WRAPPER postgres_fdw 
OPTIONS (host '<redshift_ip>',
 port '<port>',
 dbname '<db>',
 sslmode 'require');  

CREATE USER MAPPING FOR <rds_pg_user> SERVER foreign_server OPTIONS 
(user '<redshift_user>',
password '<pwd>');
```

- Permite copiar ou sincronizar dados entre **RDS PostgreSQL** e **Redshift**.
- Bom para **migra√ß√£o gradual** ou **integra√ß√£o de sistemas legados**.
---
## Resumo dos pontos-chave
- **Escala**: vertical/horizontal, com migra√ß√£o autom√°tica (downtime m√≠nimo).
- **Distribui√ß√£o**: escolha correta do distribution style √© vital para performance.
- **Ingest√£o/exporta√ß√£o**: COPY e UNLOAD s√£o eficientes; agora com op√ß√µes de streaming e Aurora zero-ETL.
- **Backup/DR**: snapshots podem ser replicados entre regi√µes com KMS.
- **Integra√ß√£o**: DBLINK facilita migra√ß√£o/integra√ß√£o com PostgreSQL.
---
# Integra√ß√µes do Amazon Redshift com outros servi√ßos da AWS

### 1. **Amazon S3**
- **Integra√ß√£o principal**:
    - `COPY` ‚Üí Importa dados do S3 para tabelas no Redshift.
    - `UNLOAD` ‚Üí Exporta resultados de queries do Redshift para S3 (em CSV, Parquet, etc.).
    - **Redshift Spectrum** ‚Üí Permite consultar **diretamente dados no S3** (em formatos como Parquet, ORC, JSON, CSV), sem precisar carreg√°-los para dentro do cluster.
- **Uso t√≠pico:**
    - Ingest√£o de dados brutos em um _data lake_.
    - Armazenamento hist√≥rico barato e quase ilimitado.
    - Integra√ß√£o com Athena, Glue, EMR.
---
### 2. **Amazon DynamoDB**
- **Integra√ß√£o via `COPY`:**
    - Voc√™ pode carregar uma tabela inteira do DynamoDB diretamente para dentro do Redshift.
    - √ötil para **sincronizar dados transacionais** (OLTP ‚Üí OLAP).
- **Uso t√≠pico:**
    - Empresas que usam DynamoDB como banco de opera√ß√µes transacionais (e-commerce, jogos, IoT).
    - Depois precisam analisar dados hist√≥ricos/anal√≠ticos no Redshift.
---
### 3. **Amazon EMR e Amazon EC2**
- **Integra√ß√£o via SSH + `COPY`:**
    - Redshift pode importar dados diretamente de clusters EMR (Hadoop/Spark) ou inst√¢ncias EC2.
    - Os dados precisam estar acess√≠veis via arquivo/host remoto.
- **Uso t√≠pico:**
    - Processar dados em **Spark/EMR** e depois carregar resultados no Redshift.
    - Pipelines h√≠bridos (pr√©-processamento em EC2/EMR, an√°lise em Redshift).
---
### 4. **AWS Data Pipeline**
- **Integra√ß√£o para orquestra√ß√£o de dados:**
    - Automatiza movimenta√ß√£o, transforma√ß√£o e carga de dados.
    - Pode mover dados entre **S3, DynamoDB, RDS, Redshift** e outros servi√ßos.
- **Uso t√≠pico:**
    - ETL programado para carregar dados diariamente/horariamente em Redshift.
    - Pipelines que unem dados de m√∫ltiplas fontes.
---
### 5. **AWS Database Migration Service (DMS)**
- **Integra√ß√£o para migra√ß√£o cont√≠nua ou inicial:**
    - Permite migrar bancos de dados existentes para Redshift.
    - Suporta migra√ß√£o com **replica√ß√£o em tempo real (CDC ‚Äì Change Data Capture)**.
- **Uso t√≠pico:**
    - Migrar de um data warehouse legado (Oracle, Teradata, SQL Server) para Redshift.
    - Manter sincroniza√ß√£o cont√≠nua enquanto a empresa faz a transi√ß√£o.
---
## Workload Management (WLM)
√â o mecanismo do Redshift para **gerenciar e priorizar cargas de trabalho concorrentes**.  
Em vez de todas as queries competirem igualmente pelos recursos do cluster, o WLM organiza as queries em **filas (queues)**, cada uma com **regras de execu√ß√£o, limites de concorr√™ncia e prioridades**.
### Por que isso √© necess√°rio?
- Sem WLM, queries grandes (ex.: um join de bilh√µes de linhas) poderiam bloquear queries r√°pidas (ex.: SELECT de 100 linhas).
- O WLM evita gargalos, garantindo que **consultas curtas e importantes n√£o fiquem presas atr√°s de consultas longas**.
### Como funciona
1. **Filas de execu√ß√£o (query queues):**
    - Cada fila pode ser configurada com:
        - N√∫mero m√°ximo de queries concorrentes.
        - Aloca√ß√£o de mem√≥ria.
        - Tempo limite.
        - Regras de prioridade.
2. **Classes de servi√ßo:**
    - Definem a qual fila cada query pertence.
    - Exemplo: consultas de BI ‚Üí fila 1, ETL batch ‚Üí fila 2.
3. **Execu√ß√£o:**
    - Queries entram na fila de acordo com regras (usu√°rio, grupo, tag, tipo de query).
    - Se a fila estiver cheia, queries aguardam.
    - O Redshift pode permitir **query hopping** (migrar queries de uma fila para outra).
---
# Tipos de WLM
### 1. **Manual WLM**
- Voc√™ configura manualmente:
    - At√© **8 filas**.
    - Concorr√™ncia, mem√≥ria e prioridades de cada fila.
- Exemplo:
    - Fila 1: at√© 5 queries curtas, timeout 60s.
    - Fila 2: at√© 3 queries pesadas de ETL, timeout 1h.
### 2. **Automatic WLM**
- O Redshift usa **machine learning** para:
    - Ajustar dinamicamente concorr√™ncia e mem√≥ria.
    - Criar at√© **8 filas autom√°ticas**.
    - Detectar queries curtas x longas e priorizar automaticamente.
---
### Recursos adicionais do WLM
- **Concurrency Scaling:** cria clusters tempor√°rios adicionais quando h√° excesso de queries.
- **Short Query Acceleration (SQA):** detecta queries curtas e as executa imediatamente em uma √°rea dedicada, sem esperar fila.
- **Query Monitoring Rules (QMR):** permite definir regras autom√°ticas (ex.: cancelar queries que usam >100 GB de mem√≥ria).
---
###  Benef√≠cios do WLM
- Melhor **tempo de resposta** para queries curtas.
- Menos **bloqueios e filas longas**.
- Mais **previsibilidade** para usu√°rios de BI e ETL.
- Possibilidade de **isolar workloads** (ex.: n√£o deixar um job batch derrubar os dashboards).
---
üìå **Resumo:**  
O **WLM √© o ‚Äúgerente de tr√¢nsito‚Äù do Redshift** ‚Üí decide quem vai primeiro, quem espera e quem usa mais pista (mem√≥ria/CPU).
## O que √© Concurrency Scaling no Redshift?
√â um recurso que permite ao Redshift **criar automaticamente clusters adicionais tempor√°rios** para lidar com picos de consultas simult√¢neas (especialmente **leitura**).
- Funciona como um **‚Äúclone tempor√°rio‚Äù** do seu cluster.
- Escala horizontalmente para processar queries em paralelo. 
- Quando a carga normaliza, esses clusters extras s√£o desligados.
---
## Por que √© importante?
- Sem ele ‚Üí consultas entram em fila quando h√° muitos usu√°rios simult√¢neos.
- Com ele ‚Üí o Redshift processa **praticamente ilimitadas consultas simult√¢neas**.
- Evita gargalos em cen√°rios de BI, dashboards e analytics.
---
## Como funciona na pr√°tica
1. Voc√™ habilita o recurso no cluster.
2. O Redshift detecta que uma fila do **Workload Management (WLM)** est√° congestionada.
3. Ele automaticamente **redireciona queries para um cluster de Concurrency Scaling**.
4. Assim, os usu√°rios n√£o percebem atraso.
‚ö° Detalhe: Voc√™ pode configurar **quais filas do WLM** podem ou n√£o usar o Concurrency Scaling.
---
##  Custos
- Voc√™ recebe **1 hora gratuita de Concurrency Scaling por dia para cada hora de uso de cluster**.
- Se ultrapassar isso ‚Üí cobra por segundo de uso extra.
- Por isso, √© importante selecionar **quais queries realmente merecem** esse recurso (ex.: dashboards de executivos, e n√£o ETL batch).
---
## Benef√≠cios
- **Elasticidade autom√°tica** ‚Üí escala para milhares de usu√°rios de BI sem precisar superprovisionar o cluster.
- **Controle granular** ‚Üí decide quais workloads podem escalar.
- **Integra√ß√£o com WLM** ‚Üí s√≥ filas espec√≠ficas aproveitam.
- **Escalabilidade transparente** ‚Üí usu√°rios finais nem percebem.    
---
## Compara√ß√£o r√°pida
- **Resizing (Elastic Resize / RA3 Managed Storage):** muda o tamanho do cluster (mais n√≥s, mais capacidade total).
- **Concurrency Scaling:** cria c√≥pias tempor√°rias para aguentar rajadas de consultas.  
    üëâ Eles se complementam, mas n√£o s√£o a mesma coisa.
---
üìå **Resumo estilo exame:**  
O **Concurrency Scaling** permite ao Redshift **criar clusters tempor√°rios sob demanda** para lidar com picos de consultas simult√¢neas, de forma autom√°tica e transparente, reduzindo filas de espera. Voc√™ controla via **Workload Management (WLM)** quais filas podem usar o recurso.

---
#  Resizing de Clusters
- **Elastic Resize**:
    - R√°pido (minutos).
    - Adiciona/remove n√≥s do mesmo tipo.
    - Pode trocar tipo de n√≥, mas cria novo cluster (causa downtime curto).
    - Limite: alguns tipos s√≥ permitem dobrar ou reduzir pela metade.
- **Classic Resize**:
    - Lento (horas/dias).
    - Muda tipo/n√∫mero de n√≥s.
    - Snapshot + restore ‚Üí cluster fica dispon√≠vel em modo leitura.
    - √ötil para grandes mudan√ßas (ex.: dc2 ‚Üí ra3).
---
## **VACUUM no Redshift**

O comando `VACUUM` √© usado para **otimizar tabelas**.  
Ele lida com dois pontos principais:
- **Recuperar espa√ßo** das linhas exclu√≠das.
- **Restaurar a ordem de classifica√ß√£o** da tabela (segundo a sort key).
## Tipos de VACUUM
1. **VACUUM FULL (padr√£o)**
    - Reordena todas as linhas **e** recupera espa√ßo das linhas exclu√≠das.
2. **VACUUM DELETE ONLY**
    - Recupera apenas espa√ßo de linhas deletadas.
    - N√£o reordena a tabela.
3. **VACUUM SORT ONLY**
    - Apenas reordena as linhas da tabela.
    - N√£o recupera espa√ßo em disco.
4. **VACUUM REINDEX**
    - Recria os √≠ndices intercalados (interleaved sort keys).
    - Reanalisa a distribui√ß√£o de valores e depois executa um VACUUM completo.
üëâ Importante: VACUUM pode ser **pesado em clusters grandes** ‚Üí boas pr√°ticas s√£o agendar em per√≠odos de baixa carga ou automatizar com **AWS Glue / Lambda / Scripts**.
---
# üîπ Novos recursos
- **RA3 nodes (managed storage)**
    - Escalam compute e storage de forma independente.
    - Baseados em SSD.
- **Data lake export**
    - UNLOAD para S3 em **Parquet** (at√© 2x mais r√°pido, 6x menos espa√ßo).
    - Compat√≠vel com Spectrum, Athena, EMR, SageMaker.
    - Suporta **particionamento autom√°tico**.
- **Spatial data types** ‚Üí GEOMETRY e GEOGRAPHY.
- **Cross-region data sharing** ‚Üí compartilhar dados ao vivo entre clusters Redshift (sem c√≥pia).
    - Suporta entre contas, entre regi√µes.
    - Exige RA3.
---
## Amazon Redshift ML (Machine Learning)
![[Pasted image 20250910185701.png]]
### ‚úÖ O que √©?
- Introduzido em **2021**.
- Permite **criar, treinar e usar modelos de ML** diretamente a partir de consultas **SQL** no Redshift.
- Usa **Amazon SageMaker Autopilot** por tr√°s dos panos.
---
### üîÑ Como funciona
1. **Exporta√ß√£o de dados** ‚Üí Redshift exporta dados de treinamento para o **Amazon S3**.
2. **Treinamento autom√°tico** ‚Üí SageMaker Autopilot:
    - Pr√©-processa os dados.
    - Escolhe o melhor algoritmo.
    - Ajusta hiperpar√¢metros.
3. **Implanta√ß√£o** ‚Üí O modelo √© registrado como uma **fun√ß√£o SQL** dentro do Redshift.
4. **Infer√™ncia** ‚Üí Voc√™ pode chamar previs√µes em tempo real via SQL (`SELECT predict_model(...)`).
---
### ‚öôÔ∏è Por baixo do cap√¥
- Redshift apenas **orquestra**.
- O **SageMaker** faz o treino pesado.
- O **S3** √© usado para armazenar dados de treino, artefatos e trocas entre Redshift ‚Üî SageMaker.

---
### üí∞ Custos
- **Treinamento e infer√™ncia** ‚Üí cobrados no **Amazon SageMaker**.
- **Armazenamento** ‚Üí cobrado no **Amazon S3**.
- **Uso do Redshift ML** ‚Üí incluso no Redshift, mas consome recursos do cluster.
---
### üìå Pontos importantes para lembrar
- Criar modelo com:
```SQL
CREATE MODEL my_model FROM (SELECT col1, col2, label FROM my_table) 
TARGET label 
FUNCTION predict_my_model 
IAM_ROLE 'arn:aws:iam::123456789012:role/MyRedshiftRole';
```
    
- A fun√ß√£o `predict_my_model` fica dispon√≠vel como UDF.
- **√â assunto perif√©rico**: pode cair em **exames de Data Analytics**, mas o aprofundamento est√° no exame de **Machine Learning Specialty**.
---

üëâ Resumindo em uma frase:  
**Redshift ML permite treinar e usar modelos de ML via SQL no Redshift, usando SageMaker Autopilot e S3 nos bastidores.**

---
## **Antipadr√µes do Redshift**
Situa√ß√µes em que **n√£o usar Redshift**:
- **Conjuntos de dados pequenos** ‚Üí melhor usar **RDS** ou at√© **Aurora**.
- **Workloads OLTP (transacionais)** ‚Üí melhor **RDS** ou **DynamoDB**.
- **Dados n√£o estruturados** ‚Üí usar **S3 + Glue/EMR** para ETL antes de Redshift.
- **Armazenamento de blobs (arquivos grandes bin√°rios)** ‚Üí n√£o guardar no Redshift; guardar no **S3** e apenas manter refer√™ncias no warehouse.
---
## Seguran√ßa
- **HSM (Hardware Security Module)**: para criptografia avan√ßada.
- Migra√ß√£o de cluster n√£o criptografado ‚Üí criar novo cluster criptografado e mover dados.
- **Controle de acesso via SQL**:

  ```SQL
 GRANT SELECT ON table foo TO bob;
 REVOKE INSERT ON table bar FROM alice;
 ```
- Integra√ß√£o com IAM, KMS, VPC, Enhanced VPC Routing.
---
#  Redshift Serverless
- **Sem clusters fixos** ‚Üí endpoint serverless.
- **Escalabilidade autom√°tica** ‚Üí paga s√≥ pelo uso.
- Ideal para:
    - Workloads vari√°veis ou espor√°dicas.
    - Ambientes de desenvolvimento/teste.
    - An√°lises ad-hoc (BI, queries explorat√≥rias).
- Usa ML para balancear custo vs performance.
---
‚úÖ **Resumo final**:  
Amazon Redshift hoje n√£o √© s√≥ um **DW em cluster** ‚Äî ele virou uma **plataforma h√≠brida** que suporta:
- Clusters cl√°ssicos (com resize el√°stico/cl√°ssico).
- **Serverless** para workloads imprevis√≠veis.
- Integra√ß√£o total com o ecossistema AWS (S3, DynamoDB, Aurora, Kinesis, EMR, SageMaker).
- Recursos modernos: RA3 nodes, Spectrum, Lake Export, Cross-Region Sharing.
- Ferramentas de gest√£o de workload (WLM, SQA, Concurrency Scaling).
- ---
## Amazon Redshift Serverless
### O que √©
- Novo modo de execu√ß√£o do **Amazon Redshift**.
- N√£o h√° cluster provisionado manualmente.
- O Redshift **provisiona e escala automaticamente** recursos para a carga de trabalho.
- Usa **Machine Learning interno** para prever e otimizar recursos em workloads vari√°veis.
- Ideal para **cargas intermitentes, testes, ambientes de dev ou an√°lises ad hoc**.
---
### Provisionamento e Configura√ß√£o
- S√≥ precisa definir:
    - **Nome do banco de dados**
    - **Credenciais do admin**
    - **VPC**
    - **Configura√ß√£o de criptografia** (padr√£o: chave **KMS da AWS**)
    - **Fun√ß√£o IAM** com permiss√µes `redshift-serverless:*`
    - **Logs de auditoria opcionais**
- Ap√≥s configura√ß√£o, voc√™ recebe:
    - **Endpoint sem servidor** (para JDBC/ODBC)
    - **Editor de consultas no console**
- **Snapshots e pontos de recupera√ß√£o** ainda est√£o dispon√≠veis.
---
### Custos e Dimensionamento
- Capacidade medida em **Redshift Processing Units (RPU‚Äôs)**.
- **Faturamento**:
    - **Por segundo** de uso ‚Üí convertido em **RPU-hours**.
    - - **Armazenamento** (por GB/m√™s).    
- **Configura√ß√£o de capacidade**:
    - **Base RPU‚Äôs**: 32 a 512 (padr√£o AUTO).
    - **Max RPU‚Äôs**: define limite superior ‚Üí controla custos.
- Caso t√≠pico:
    - Baixar RPU para economizar üíµ.
    - Aumentar RPU para mais throughput ‚ö°.
---
### Limita√ß√µes do Serverless
- N√£o suporta:
    - **Parameter Groups**
    - **Workload Management (WLM)**
    - **Parcerias AWS Partner Connect**
    - **Janelas de manuten√ß√£o/version tracks** (atualiza√ß√µes podem interromper conex√µes sem aviso)
    - **Endpoints p√∫blicos** ‚Üí acesso **apenas via VPC**
---
### üìä Monitoramento
- **Views internas**:
    - `SYS_QUERY_HISTORY` ‚Üí hist√≥rico de queries
    - `SYS_LOAD_HISTORY` ‚Üí hist√≥rico de cargas
    - `SYS_SERVERLESS_USAGE` ‚Üí consumo de RPUs
- **CloudWatch Logs**:
    - Conex√µes e usu√°rios (ativados por padr√£o)
    - Logs de atividade de usu√°rio (opcionais)
- **CloudWatch Metrics**:
    - `QueriesCompletedPerSecond`
    - `QueryDuration`
    - `QueriesRunning`
    - Dimens√µes: `DatabaseName`, `Latency` (short/medium/long), `QueryType`, `Stage`
---
### Em resumo
**Redshift Serverless** = Redshift com cobran√ßa por **RPUs em uso** + **escala autom√°tica de recursos**, sem precisar gerenciar clusters.  

**Mais simples, mais flex√≠vel, mas com algumas limita√ß√µes importantes (WLM, manuten√ß√£o, endpoints p√∫blicos).**

---
## Amazon Redshift ‚Äì Materialized Views (MV)
### ‚úÖ O que s√£o

- **Views normais** ‚Üí armazenam apenas a _defini√ß√£o da query_, e cada execu√ß√£o roda de novo sobre as tabelas base.
- **Materialized Views (MV)** ‚Üí armazenam o **resultado pr√©-computado da query**, como se fosse uma tabela est√°tica.
- Grande benef√≠cio: **desempenho** em consultas complexas e recorrentes.
###   Benef√≠cios
- Consultas **mais r√°pidas**, pois acessam resultados prontos.
- **Evita recomputar** joins pesados, agrega√ß√µes ou c√°lculos repetitivos.
- Excelente para **dashboards recorrentes** (ex: Amazon QuickSight).
- Pode ser **empilhada**: uma MV pode ser constru√≠da sobre outra MV.
### Desafios
- **Problema de sincroniza√ß√£o**:
    - Como os dados s√£o armazenados, podem ficar **desatualizados** em rela√ß√£o √†s tabelas base.
- Requer **refresh** expl√≠cito ou autom√°tico.
### Como usar
Para criar 
``` SQL
CREATE MATERIALIZED VIEW mv_example AS
SELECT user_id, COUNT(*) AS orders
FROM orders
GROUP BY user_id;
```
Consultar
```SQL
SELECT * FROM mv_example;
```
Atualizar
```SQL
REFRESH MATERIALIZED VIEW mv_example;
```
### Exemplos de uso
- Dashboards que precisam de **respostas r√°pidas**.
- Relat√≥rios com **JOINs ou agrega√ß√µes complexas**.
- Workloads de BI que repetem sempre as mesmas queries.
### Pontos-chave para exame

- **MV ‚â† View normal** ‚Üí armazena resultado, n√£o s√≥ query.
- **Otimiza√ß√£o de desempenho** em queries recorrentes.
- Precisa de **refresh** (manual ou autom√°tico).
- Pode ser constru√≠da **sobre outras MVs**.
---
## O que √© o **Redshift Data Sharing**
√â um recurso que permite compartilhar **dados em tempo real, de forma segura, somente leitura**, entre clusters do Redshift (produtor ‚Üí consumidor), sem precisar **copiar nem mover os dados**.
Isso significa que:
- Os dados continuam centralizados no **cluster produtor**.
- Os **clusters consumidores** acessam uma vis√£o transacional consistente (live, n√£o snapshots).
- O desempenho do cluster produtor **n√£o √© afetado** pela carga do cluster consumidor.
---
###  Por que usar?
1. **Isolamento de carga de trabalho**
    - Evita que consultas pesadas de times/departamentos diferentes degradem o cluster principal.
    - O consumidor roda em outro cluster, independente.
2. **Colabora√ß√£o entre times**
    - Times diferentes podem acessar os mesmos dados em tempo real.
    - Exemplo: marketing e finan√ßas acessando os dados sem duplica√ß√£o.
3. **Ambientes Dev/Test/Prod**
    - Usar os mesmos dados produtivos em dev/test, sem risco de afetar o ambiente produtivo.
4. **Monetiza√ß√£o de dados**
    - Compartilhar dados com parceiros via **AWS Data Exchange**.
    - Exemplo: vender datasets de mercado financeiro, geogr√°ficos, sa√∫de etc.
---
### O que pode ser compartilhado?
- Bancos de dados inteiros
- Schemas
- Tabelas
- Views
- UDFs (fun√ß√µes definidas pelo usu√°rio)
Com controle refinado de acesso ‚Üí o produtor define exatamente o que √© vis√≠vel.
---
### Como funciona na pr√°tica
- **Produtor**: cluster que cont√©m os dados originais.
- **Consumidor**: cluster que recebe acesso de leitura aos dados.
- Os dados s√£o transacionalmente consistentes e sempre ‚Äúao vivo‚Äù.
- Ambos os clusters precisam:
    - Usar **RA3 nodes**
    - Estar **criptografados**
- **Cross-region sharing** √© poss√≠vel, mas gera cobran√ßa de transfer√™ncia de dados.

---
### Tipos de Data Sharing
1. **Standard** ‚Üí compartilhamento direto entre clusters Redshift.
2. **AWS Data Exchange** ‚Üí para compartilhar com clientes/mercado.
3. **Lake Formation-managed** ‚Üí controle centralizado de seguran√ßa e governan√ßa de acesso.
---
‚úÖ Em resumo:  
O **Redshift Data Sharing** elimina a necessidade de duplicar dados entre clusters, permitindo **isolamento de workloads**, **colabora√ß√£o segura** e at√© **monetiza√ß√£o**. Ele √© especialmente √∫til quando m√∫ltiplos times/ambientes precisam de acesso aos mesmos dados, mas sem comprometer o desempenho do cluster principal.

---
## Ponto-chave de prova / pr√°tica
- **Serverless** ‚Üí paga por uso (RPU), escala autom√°tico, mas sem WLM.
- **Materialized Views** ‚Üí aceleram consultas pesadas (repetitivas).
- **Data Sharing** ‚Üí read-only, em tempo real, RA3 obrigat√≥rio, √≥timo p/ isolamento de workload.
- ---
## O que s√£o Lambda UDFs no Redshift?
- **UDFs (User Defined Functions)** ‚Üí permitem criar fun√ß√µes personalizadas dentro do banco.
- **Lambda UDFs** ‚Üí permitem que essas fun√ß√µes sejam implementadas como **fun√ß√µes AWS Lambda**, escritas em qualquer linguagem suportada (Python, Node.js, Java etc.).
Ou seja, voc√™ consegue chamar **c√≥digo externo** diretamente de uma consulta SQL no Redshift.
---
### Por que isso √© √∫til?
- Expandir o SQL para al√©m de opera√ß√µes nativas.
- Integrar Redshift com **outros servi√ßos** (IA, APIs externas, servi√ßos internos).
- Reutilizar l√≥gica j√° implementada em Lambdas.
Exemplos:
- Normaliza√ß√£o de dados com ML em Python.
- Valida√ß√£o de endere√ßos com API externa.
- Convers√£o de formatos especiais (ex: XML ‚Üí JSON).
<p align="center">
  <img src="Pasted image 20250920110413.png" >
</p>
- ---
### Como funciona
1. **Registrar a fun√ß√£o** no Redshift via `CREATE EXTERNAL FUNCTION`.
2. Conceder permiss√£o com `LANGUAGE EXFUNC`.
3. Associar a fun√ß√£o a uma Lambda j√° existente.
üìå Exemplo simplificado:
```SQL
CREATE EXTERNAL FUNCTION exfunc_sum(a int, b int)
RETURNS int
VOLATILE
LAMBDA 'my-lambda-function-name'
IAM_ROLE 'arn:aws:iam::123456789012:role/MyRedshiftLambdaRole';
```
Uso
```SQL
SELECT exfunc_sum(10, 5); -- retorna 15
```
---
### Permiss√µes
- √â necess√°rio uma **IAM Role** associada ao Redshift que permita `lambda:InvokeFunction`.
- Essa role √© passada no `CREATE EXTERNAL FUNCTION`.
- Pode chamar **Lambdas em outras contas**, usando **role chaining**.
- ---
### Como o Redshift envia os dados ao Lambda
- A comunica√ß√£o √© feita via **JSON payload**.
- O Lambda recebe:
    - `requestId`, `cluster`, `dbUser`, `externalFunction`, `queryId`
    - Argumentos para N registros em batch (ex: 4 linhas da consulta).
    - 
Exemplo payload recebido pelo Lambda:
```JSON
{
  "requestId": "1234",
  "cluster": "redshift-cluster-1",
  "dbUser": "admin",
  "externalFunction": "exfunc_sum",
  "queryId": "5678",
  "numRecords": 4,
  "arguments": [
    [3, 5],
    [7, 2],
    [10, 10],
    [6, 8]
  ]
}
```
Resposta
```JSON
{
  "success": true,
  "results": [8, 9, 20, 14]
}
```
---
### Benef√≠cios
‚úÖ Pode usar **qualquer linguagem** suportada pelo Lambda.  
‚úÖ Pode chamar **outros servi√ßos AWS ou externos**.  
‚úÖ Pode aplicar **l√≥gica complexa** em consultas SQL.
### Limita√ß√µes
‚ö†Ô∏è Depende da lat√™ncia da chamada Lambda ‚Üí cuidado com uso em queries cr√≠ticas.  
‚ö†Ô∏è Custo de invoca√ß√µes Lambda pode escalar se abusar.  
‚ö†Ô∏è Deve-se controlar seguran√ßa (permiss√µes IAM).

---
## Redshift Federated Queries
Permite que o **Amazon Redshift** consulte dados **externos** em:
- **Amazon RDS (PostgreSQL e MySQL)**
- **Amazon Aurora (PostgreSQL e MySQL)**
- **Lagos de dados no S3 via Redshift Spectrum**
<p align="center">
  <img src="Pasted image 20250920113318.png" >
</p>
Isso evita ETL e movimenta√ß√£o desnecess√°ria de dados, permitindo **consultar dados em tempo real diretamente na fonte**.

---
### Como funciona?
1. **Conectividade**
    - Redshift e RDS/Aurora precisam estar na mesma **VPC** ou com **VPC Peering**.
    - N√£o pode haver sobreposi√ß√£o de IPs.
2. **Autentica√ß√£o**
    - Credenciais armazenadas no **AWS Secrets Manager**.
    - IAM Role do Redshift precisa ter permiss√£o para acessar esses segredos.
3. **Configura√ß√£o**
    - Criar um **External Schema** no Redshift:
```SQL
CREATE EXTERNAL SCHEMA apg
FROM POSTGRES
DATABASE 'database-1'
SCHEMA 'myschema'
URI 'aurora-cluster-endpoint'
IAM_ROLE 'arn:aws:iam::123456789:role/RedshiftRole'
SECRET_ARN 'arn:aws:secretsmanager:...';
```
Consultas podem ent√£o referenciar tabelas externas:
```SQL
SELECT COUNT(*) FROM apg.lineitem;
```
**Execu√ß√£o**
- Parte da computa√ß√£o √© empurrada para o RDS/Aurora.
- Redshift s√≥ traz os resultados necess√°rios.
---
## Restri√ß√µes
- **Somente leitura** sobre fontes externas.
- **Custos extras** podem ocorrer no RDS/Aurora pelo aumento de tr√°fego e carga.
- **Unidirecional** ‚Üí Redshift acessa RDS/Aurora, mas n√£o o contr√°rio.
---
## Para lembrar no exame
- Federated Queries **‚â† ETL** ‚Üí Consulta em tempo real, sem copiar dados.
- Necess√°rio **Secrets Manager + IAM Role**.
- Visualiza√ß√£o √∫til: `SVV_EXTERNAL_SCHEMAS` mostra os schemas externos configurados.
- Funciona para **Postgres/MySQL (RDS e Aurora)** + **S3**.
---
## Tipos de tabelas e views do sistema no Redshift

1. **SYS**
    - Come√ßam com `SYS_`.
    - Focadas em **monitoramento de consultas e uso de workload**.
    - Muito usadas para tunning e troubleshooting.
2. **STV**
    - "System Table Virtual".
    - Cont√™m **dados transit√≥rios**, ou seja, **instant√¢neos em mem√≥ria** do que est√° acontecendo agora no cluster.
    - Exemplo: status de n√≥s, sess√µes, queries em execu√ß√£o no momento.
3. **SVV**
    - "System View Virtual".
    - S√£o **views baseadas nas STV**, exp√µem metadados de forma amig√°vel.
    - Exemplo: `SVV_TABLE_INFO` (info de tabelas, distribui√ß√£o, sort keys, compress√£o).
4. **STL**
    - "System Table Log".
    - S√£o **logs persistentes em disco**.
    - Registram o **hist√≥rico de queries, erros, etapas de execu√ß√£o**.
    - Exemplo: `STL_QUERY` (log de queries executadas).
5. **SVL**
    - "System View Log".
    - **Views baseadas nos logs STL**.
    - Trazem informa√ß√µes detalhadas sobre queries e execu√ß√£o no **cluster principal**.
    - Exemplo: `SVL_QLOG` (detalhes de execu√ß√£o das queries).
6. **SVCS**
    - Usadas para **detalhes de consultas em clusters principais e de concurrency scaling**.
    - Permitem entender como a carga est√° sendo distribu√≠da.
### Exemplo pr√°tico
Consulta do instrutor (tempo de execu√ß√£o das queries do √∫ltimo dia):
```SQL
SELECT
    q.query,
    q.starttime,
    q.endtime,
    DATEDIFF(ms, q.starttime, q.endtime) AS runtime_ms,
    q.aborted
FROM stl_query q
JOIN svl_qlog l
  ON q.query = l.query
WHERE q.starttime >= GETDATE() - INTERVAL '1 day'
ORDER BY q.starttime DESC;
```
- `STL_QUERY` ‚Üí hist√≥rico de queries (log em disco).
- `SVL_QLOG` ‚Üí detalhes de execu√ß√£o.
- O join entre eles d√° uma vis√£o bem completa: **quando rodou, quanto demorou, se falhou**.

**Resumo para fixar:**
- **STV** = snapshot em mem√≥ria.
- **SVV** = views sobre STV (metadados).
- **STL**= logs em disco.
- **SVL** = views sobre STL.
- **SYS** = monitoramento de workload.
- **SVCS** = detalhes de consultas em clusters principais e de scaling.
---
##  O que √© a Redshift Data API?
- Um **endpoint HTTP seguro** para executar **instru√ß√µes SQL** em clusters Redshift (provisionados ou serverless).
- Permite consultas **individuais** ou **em lote**.
- **Dispensa drivers ODBC/JDBC** ‚Üí n√£o precisa manter conex√µes tradicionais.
- Usa **AWS SDK / REST API**, ou seja, pode ser chamada de qualquer linguagem suportada pelo SDK (Python, Java, Go, etc).
![[Pasted image 20250920115442.png]]
---
## Como funciona
1. O app chama `ExecuteStatement` ou `BatchExecuteStatement`.  
    ‚Üí a API retorna um **statementId**.
2. O app chama `DescribeStatement` para ver status (pendente, executando, conclu√≠do, erro).
3. O app chama `GetStatementResult` para recuperar o resultado.
4. Se necess√°rio, pode usar `CancelStatement` para abortar.
---
## Seguran√ßa
- **N√£o envia senhas**.
- Usa **AWS Secrets Manager** ou **credenciais tempor√°rias** para autenticar.
- Controle de acesso via **IAM policies**.
- Integra com **CloudTrail** ‚Üí auditoria de chamadas de API.
---
## Limites Importantes (caem muito em prova!)

- ‚è± **Consulta**: at√© 24h de dura√ß√£o.
- üîÑ **Consultas ativas**: at√© **500** por vez.
- üìÇ **Resultado**: at√© **100 MB (gzip)**, armazenado por 24h.
- üìú **Tamanho do comando SQL**: at√© **100 KB**.
- üìè **M√°x. de dados por linha**: **64 KB**.
- üîë **Token de cliente**: v√°lido por at√© 8h.
- üö¶ **TPS**: por exemplo, `ExecuteStatement` ‚Üí at√© 30 transa√ß√µes por segundo.
---
## Integra√ß√µes comuns
- **Aplica√ß√µes customizadas** (via SDK ou REST).
- **Step Functions** ‚Üí orquestra√ß√£o de ETL.
- **SageMaker Notebooks** ‚Üí an√°lises de ML direto no Redshift.
- **EventBridge** ‚Üí
    - disparar queries em eventos,
    - agendar execu√ß√£o peri√≥dica,
    - ou at√© **streaming de resultados**.
---
## Vantagens principais

‚úÖ Sem drivers ou conex√µes complexas.  
‚úÖ Funciona **fora da AWS**.  
‚úÖ Bom para **serverless apps** e **workflows event-driven**.  
‚úÖ Integra-se com IAM, Secrets Manager, EventBridge, CloudTrail.

**Resumo r√°pido para exame**:

> A Data API fornece acesso seguro ao Redshift via HTTP/SDK, sem drivers, usando Secrets Manager ou credenciais tempor√°rias. √â ass√≠ncrona, com limites de 24h de execu√ß√£o, 100MB de resultados e 64KB por linha. Se integra com Step Functions, EventBridge e SageMaker.