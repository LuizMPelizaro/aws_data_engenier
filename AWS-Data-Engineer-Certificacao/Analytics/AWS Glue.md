# AWS Glue
#tema/analytics
## O que √© o AWS Glue?
- **Servi√ßo serverless** (sem servidor, totalmente gerenciado).
- Usado para **ETL** (extra√ß√£o, transforma√ß√£o e carga de dados).
- Faz **descoberta de esquema** e mant√©m um **cat√°logo de metadados**.
- Atua como a ‚Äúcola‚Äù entre dados n√£o estruturados (ex.: no S3) e ferramentas de an√°lise estruturada (Athena, Redshift, EMR, QuickSight etc.).
---
## Componentes e fun√ß√µes
1. **Crawler (Rastreador):**
    - Examina os dados (ex.: no S3).
    - Descobre colunas, tipos de dados, nomes e localiza√ß√£o.
    - Preenche o **Glue Data Catalog** (tabelas virtuais).
    - Pode rodar sob demanda ou em agenda.    
2. **Glue Data Catalog:**
    - Reposit√≥rio central de **metadados**.
    - Faz os dados no S3 parecerem **tabelas estruturadas**.
    - Permite consultas via **SQL** em ferramentas como Athena, Redshift Spectrum ou Hive no EMR.
    - Importante: **os dados continuam no S3**, n√£o s√£o copiados.
3. **Glue ETL Jobs:**
    - Rodam usando **Apache Spark** por baixo.
    - Transformam e processam os dados.
    - Podem ser agendados, sob demanda ou disparados por eventos.
---
## Import√¢ncia no exame AWS
- Depois que tiraram ML do exame de Big Data, **Glue e Redshift ganharam mais peso**.
- O essencial: entender como o Glue conecta servi√ßos e organiza dados para an√°lise.

---
## Parti√ß√µes (Glue + S3)
- O Glue n√£o faz m√°gica: a **organiza√ß√£o dos dados no S3 importa muito**.
- O **particionamento** define a efici√™ncia das consultas.
- Exemplo:
    - Se consultas s√£o por **tempo** ‚Üí organizar como `ano/mes/dia/dispositivo`.
    - Se consultas s√£o por **dispositivo** ‚Üí organizar como `dispositivo/ano/mes/dia`.
- Isso evita escanear dados desnecess√°rios e reduz custo/tempo de execu√ß√£o no Athena ou Redshift Spectrum.
---
‚úÖ Em resumo:  
O Glue √© como um **cat√°logo inteligente** + **motor ETL Spark gerenciado**, que transforma dados ‚Äúbagun√ßados‚Äù (n√£o estruturados) em algo que pode ser consultado com SQL, sem mover do S3.

---
## AWS Glue + Hive (Explica√ß√£o Avan√ßada)
##  1. Papel do AWS Glue
O **AWS Glue** √© um servi√ßo **serverless de integra√ß√£o de dados** que atua em duas frentes principais:
1. **Data Catalog** (metadados centralizados e esquemas).
2. **ETL distribu√≠do** (baseado em Spark, para transformar e preparar dados).
No ecossistema AWS, ele **conecta dados n√£o estruturados (ex: S3) a engines anal√≠ticas** (Athena, Redshift Spectrum, EMR, etc.), permitindo consultas **SQL-like** em dados originalmente sem esquema.
---
##  2. Integra√ß√£o com Apache Hive
- **Hive Metastore**: no mundo Hadoop/EMR, o Hive usa um banco relacional (tipicamente MySQL/Postgres) para armazenar metadados (schemas, tabelas, parti√ß√µes).
- O **Glue Data Catalog** pode **substituir o Hive Metastore**.
    - Isso significa que qualquer cluster EMR rodando Hive pode ser configurado para usar o Glue Data Catalog como **√∫nica fonte de metadados**.
- **Migra√ß√£o bidirecional**:
    - √â poss√≠vel importar um metastore Hive existente para o Glue.
    - Ou usar o cat√°logo do Glue como o metastore do Hive.
- Benef√≠cio: cria um **metastore unificado** para consultas em **Athena, Redshift Spectrum, EMR/Hive e at√© Spark SQL**.
---
##  3. Glue ETL ‚Äì Arquitetura
- **Jobs ETL** rodam sobre **Apache Spark gerenciado** (serverless).
- Voc√™ pode:
    - Usar a interface visual para criar pipelines.
    - Ou escrever **scripts PySpark/Scala customizados**.
- **Execu√ß√£o**:
    - **Sob demanda**.
    - **Agendada (Scheduler interno)**.
    - **Event-driven** (acionado por chegada de dados em S3, por exemplo, via Lambda ou evento do S3).
---
##  4. Performance e DPUs
- **DPU (Data Processing Unit)** = unidade de computa√ß√£o do Glue.
    - Cada DPU cont√©m **4 vCPU + 16 GB RAM** (aproximadamente, dependendo da vers√£o).
    - Por padr√£o, **1 DPU √© reservada para driver + 1 executor** ‚Üí o restante √© para os executores do Spark.
- **Tuning de Jobs**:
    - Habilitar **Job Metrics** no Glue Console.
    - Comparar **executores usados vs. executores alocados**.
    - Ajustar a capacidade de DPUs com base na an√°lise.
- Exemplo:
    - Se o job consome 5 executores efetivos, mas voc√™ s√≥ alocou 2 DPUs (4 executores poss√≠veis, descontando driver), ter√° gargalo.
    - Aumentar para 4 DPUs liberaria 7 executores √∫teis.
---
##  5. Estruturas de Dados ‚Äì DynamicFrame
- O **DynamicFrame** √© a abstra√ß√£o central do Glue ETL.
- Compara√ß√£o com Spark DataFrame:
    - Ambos armazenam dados distribu√≠dos em linhas/colunas.
    - DynamicFrame √© mais flex√≠vel ‚Üí preserva metadados de ETL e tolera **schemas semi-estruturados**.
- **DynamicRecord** = cada linha, com campos autodescritivos.
- Convers√£o poss√≠vel: `DynamicFrame ‚Üî DataFrame`.
    - √ötil quando voc√™ quer usar APIs Spark que n√£o est√£o no Glue.

---
## 6. Transforma√ß√µes ETL
###  Pr√©-processamento
- `DropFields` / `DropNullFields` ‚Üí remover colunas ou valores nulos.
- `ResolveChoice` ‚Üí resolver conflitos de schema (muito cobrado em prova).
###  Opera√ß√µes Cl√°ssicas
- `Filter` ‚Üí selecionar subconjuntos, excluir outliers.
- `Join` ‚Üí enriquecer dados combinando tabelas.
- `Map` ‚Üí criar/remover campos, manipular colunas linha a linha.
###  Convers√£o de Formato
- CSV ‚Üî JSON ‚Üî Avro ‚Üî Parquet ‚Üî ORC ‚Üî XML.
- Parquet/ORC = preferidos para performance em Athena/Redshift Spectrum.
###  Machine Learning integrado
- `FindMatches ML` ‚Üí identifica duplicatas fuzzy (endere√ßos, nomes, etc.) sem chave prim√°ria exata.
---
##  7. ResolveChoice (Ambiguidade de Schema)
Quando h√° conflito (ex: duas colunas `price` com tipos diferentes):
1. **make_cols** ‚Üí cria colunas separadas (`price_double`, `price_string`).
2. **cast:type** ‚Üí for√ßa tudo para um tipo espec√≠fico.
3. **make_struct** ‚Üí cria um campo estruturado com m√∫ltiplos tipos dentro.
4. **project:type** ‚Üí mant√©m apenas um tipo.
Isso garante consist√™ncia antes de carregar dados em engines downstream (Athena, Redshift).
---
##  8. Integra√ß√µes e Destinos
O Glue ETL pode gravar dados:
- De volta no **S3** (ex: processados em Parquet).
- Via **JDBC** ‚Üí RDS, Redshift, bancos externos.
- Para o pr√≥prio **Glue Data Catalog** (ex: gerar metadados ap√≥s transforma√ß√£o).
---
## 9. Monitoramento e Alertas
- Logs e erros ‚Üí **CloudWatch Logs**.
- M√©tricas ‚Üí **Glue Console** (n√£o CloudWatch diretamente).
- Notifica√ß√µes ‚Üí **SNS** (ex: alertar falhas de jobs).
---
##  10. Ponto de Vista de Prova (AWS Certified Data Analytics ‚Äì Specialty)

- Glue = **ETL serverless baseado em Spark**.
- Substitui o **Hive Metastore** ‚Üí integra√ß√£o com EMR/Hive, Athena, Redshift.
- **DynamicFrame** = estrutura central.
- **ResolveChoice** cai bastante em quest√µes.
- **DPUs** precisam ser entendidas (driver, executores, tuning).
- ETL pode ser **event-driven, schedule ou manual**.
- Transforma√ß√µes ‚Üí limpeza, enriquecimento, convers√£o de formato, deduplica√ß√£o ML.
---
üëâ Esse √© o n√≠vel que realmente pode cair em prova e que diferencia quem s√≥ viu a introdu√ß√£o de quem entende a **profundidade do Glue**.

## Atualiza√ß√£o do Cat√°logo de Dados no Glue

### **1. Contexto**
- O Glue usa o **Data Catalog** como reposit√≥rio central de metadados.
- Normalmente, o **crawler** descobre e atualiza schemas e parti√ß√µes.
- Mas, em pipelines ETL, pode ser necess√°rio **alterar tabelas/parti√ß√µes diretamente do script**, sem depender s√≥ do crawler.
---
### **2. Formas de atualizar o cat√°logo**
####  **Op√ß√£o A ‚Äì Reexecutar o crawler**
- Simples, mas nem sempre eficiente.
- Reprocessa os dados, descobre o schema e atualiza tabelas/parti√ß√µes.
- Pode ser custoso em ambientes grandes.
####  **Op√ß√£o B ‚Äì Atualizar via script ETL**
- O pr√≥prio job pode atualizar metadados com as op√ß√µes:
    - `enableUpdateCatalog` ‚Üí habilita atualiza√ß√£o no cat√°logo.
    - `updateBehavior` ‚Üí define como atualizar (ex: sobrescrever, mesclar).
    - `partitionKeys` ‚Üí permite definir novas parti√ß√µes ao salvar.
Exemplo (PySpark com Glue):

```Python
datasink = glueContext.write_dynamic_frame.from_options(
    frame=dynamic_frame,
    connection_type="s3",
    connection_options={
        "path": "s3://meu-bucket/processed/",
        "partitionKeys": ["ano", "mes"]
    },
    format="parquet",
    transformation_ctx="datasink"
)

# Atualizar cat√°logo de dados
glueContext.purge_table(
    database="meu_banco",
    table_name="minha_tabela",
    options={"retentionPeriod": 0}
)

glueContext.write_dynamic_frame.from_catalog(
    frame=dynamic_frame,
    database="meu_banco",
    table_name="minha_tabela",
    additional_options={"enableUpdateCatalog": True, "updateBehavior": "UPDATE_IN_DATABASE"}
)

```
---
### **3. Limita√ß√µes importantes**
- S√≥ funciona se o **S3 for o armazenamento de dados**.
- Suportado apenas para formatos: **CSV, JSON, Avro, Parquet**.
- No caso de **Parquet**, pode exigir par√¢metros extras (porque √© columnar).
- **N√£o h√° suporte para schemas aninhados** na atualiza√ß√£o direta.
---
### **4. Casos pr√°ticos**
- **Adicionar novas parti√ß√µes** no ETL ‚Üí exemplo: dados por ano/m√™s/dia.
- **Atualizar esquema** ‚Üí ex: novo campo adicionado ao dataset.
- **Criar novas tabelas** direto do job ‚Üí √∫til em pipelines din√¢micos.
---
üí° **Resumo para prova:**  
Se aparecer que voc√™ precisa **modificar parti√ß√µes ou atualizar esquema durante o ETL**, a resposta √© ‚Üí **use `enableUpdateCatalog` + `updateBehavior` no script** (n√£o precisa depender do crawler).

---
## Execu√ß√£o de Jobs no AWS Glue

O Glue oferece v√°rias maneiras de executar trabalhos de ETL. Entender **quando e como usar cada m√©todo** √© essencial para projetos reais e tamb√©m para o exame.

---
### **1. Agendamento baseado em tempo (estilo Cron)**
- Voc√™ pode agendar jobs do Glue para serem executados periodicamente.
- Usa sintaxe **cron** para definir hor√°rios precisos.
- √ötil para pipelines que precisam rodar **em intervalos fixos**, como di√°rio, semanal ou hor√°rio espec√≠fico.
**Exemplo de cron:**
``` Bash
0 12 * * ? *   ‚Üí executa todo dia √†s 12h UTC
```
O Glue dispara o job automaticamente no hor√°rio definido.

---
### **2. Marcadores de Job (Job Bookmarks)**
- Um **marcador de trabalho** (job bookmark) mant√©m o estado do processamento.
- Permite **evitar reprocessar dados antigos** em jobs recorrentes.
- Funciona **com S3** (CSV, JSON, Parquet, etc.) e **bancos de dados relacionais** via JDBC.
####  Pontos importantes:
- **Processa apenas novas linhas**; n√£o lida com atualiza√ß√µes de registros existentes.
- Mant√©m um controle interno sobre at√© onde os dados foram processados.
- Ideal para pipelines de ingest√£o incremental de dados.
**Exemplo de configura√ß√£o em PySpark/Glue:**
```Python
glueContext.create_dynamic_frame.from_options(
    connection_type="s3",
    connection_options={
        "paths": ["s3://meu-bucket/dados/"],
        "recurse": True,
        "jobBookmarkOption": "job-bookmark-enable"
    },
    format="json"
)
```

---
## **3. Integra√ß√£o com CloudWatch e eventos**
- O Glue se integra ao **CloudWatch Events/Logs** para monitoramento de jobs.
- Pode disparar a√ß√µes autom√°ticas **quando um job √© bem-sucedido ou falhar**:
    - Invocar uma **Lambda**.
    - Enviar uma notifica√ß√£o via **SNS**.
    - Disparar execu√ß√£o de **EC2**, **Kinesis** ou **Step Functions**.
### üîπ Benef√≠cios:
- Cria **pipelines automatizadas e encadeadas**.
- Permite **notifica√ß√£o em tempo real** de falhas ou sucesso.
- Pode acionar workflows complexos sem interven√ß√£o manual.
**Exemplo conceitual:**
Glue Job -> CloudWatch Event -> Lambda -> Step Function -> EC2/Kinesis

---
üí° **Resumo para prova e pr√°tica:**
1. **Agendamento Cron:** para jobs peri√≥dicos.
2. **Job Bookmarks:** para processamento incremental e evitar reprocessamento.
3. **CloudWatch Events:** para automa√ß√£o, alertas e integra√ß√£o com outros servi√ßos AWS.
---
## Modelo de Custos do AWS Glue

O Glue √© **serverless** (sem precisar gerenciar infraestrutura), mas n√£o √© gratuito. O custo √© baseado principalmente em **tempo de execu√ß√£o** e **armazenamento de metadados**.

---
### **1. Cobran√ßa por processamento (ETL e Crawlers)**

- Voc√™ paga **por segundo** de execu√ß√£o dos **ETL Jobs** (baseados em Apache Spark) e dos **Crawlers**.
- O c√°lculo √© feito com base em **DPUs (Data Processing Units)**:
    - **1 DPU = 4 vCPU + 16 GB RAM**.
    - O m√≠nimo cobrado por job √© **10 minutos de execu√ß√£o**, depois √© por segundo.
üí° Isso significa que at√© jobs curtos t√™m um custo fixo inicial.
---
## **2. Armazenamento no Glue Data Catalog**
- **Primeiro 1 milh√£o de objetos** (tabelas, parti√ß√µes, esquemas) s√£o **gratuitos por m√™s**.
- Depois desse limite, cada objeto adicional armazenado ou acessado passa a ser cobrado.
üìå Em grandes data lakes, √© comum ultrapassar esse 1M, ent√£o precisa ficar de olho no custo de metadados.
---
## **3. Endpoints de Desenvolvimento (Dev Endpoints)**
- S√£o ambientes interativos (como notebooks) usados para testar e editar scripts.
- Cobrados **por minuto de uso**.
- **Aten√ß√£o**: se voc√™ esquecer um endpoint ligado, a cobran√ßa continua at√© desligar.
    - Erro cl√°ssico: ‚Äúabrir o notebook, sair para o almo√ßo e esquecer ligado‚Äù.
---
## Antipadr√µes do AWS Glue
Apesar de ser bem flex√≠vel, existem cen√°rios em que **n√£o √© recomendado** usar o Glue:
1. **V√°rios mecanismos de ETL**:
    - O Glue s√≥ usa **Apache Spark**.
    - Se voc√™ precisa rodar **Hive, Pig ou MapReduce** ‚Üí prefira o **EMR** ou **Data Pipeline**.
2. **(Antigamente) Streaming de dados**:
    - Antes de 2020, Glue s√≥ suportava ETL em lote.
    - Mas hoje isso mudou: ele suporta **ETL de streaming sem servidor**.
    - Integra com **Kinesis** e **Kafka**, processando dados em tempo real.
---
## Glue com ETL de Streaming
- Usa o recurso de **Structured Streaming do Apache Spark**.
- Em vez de processar um conjunto fixo de dados, o Spark mant√©m um **dataset em crescimento cont√≠nuo**, aplicando transforma√ß√µes em tempo real.
- Isso permite que **o mesmo c√≥digo usado em batch** possa ser facilmente adaptado para streaming.
üìå Fluxo t√≠pico:
1. Fonte de dados em **Kinesis** ou **Kafka**.
2. Job Glue Streaming ‚Üí transforma√ß√£o e limpeza em tempo real.
3. Destino: **S3, Redshift, ou outro datastore**.
---
‚úÖ **Resumo para provas e pr√°tica:**
- **Custo:**
    - ETL/Crawlers ‚Üí por segundo, com base em DPUs (m√≠nimo 10 min/job).
    - Data Catalog ‚Üí 1M objetos gr√°tis.
    - Dev Endpoints ‚Üí por minuto.
- **Antipadr√µes:**
    - N√£o usar se precisar de engines al√©m de Spark.
    - Streaming agora √© suportado (antes n√£o era).
---
## AWS Glue Studio ‚Äî O que √© e por que importa?

O **AWS Glue Studio** √© uma **interface visual e interativa** dentro do AWS Glue que simplifica a cria√ß√£o, orquestra√ß√£o e monitoramento de **pipelines ETL (Extract, Transform, Load)**.  
Enquanto o **Glue tradicional** exigia que voc√™ escrevesse scripts PySpark (ou usasse DynamicFrames/DynamicRecords manualmente), o Glue Studio traz uma camada **‚Äúlow-code/no-code‚Äù** que democratiza o uso do Glue, permitindo que at√© usu√°rios sem grande familiaridade com Spark possam criar pipelines complexos.

---
##  Principais Recursos
1. **Interface visual (ETL Visual / DAGs)**
    - Voc√™ monta fluxos de dados como um **grafo ac√≠clico direcionado (DAG)**.
    - √â poss√≠vel conectar m√∫ltiplas fontes (S3, Kinesis, Kafka, JDBC, Snowflake, BigQuery, etc.), aplicar transforma√ß√µes paralelas ou sequenciais e definir m√∫ltiplos destinos.
    - Isso √© ideal para **fluxos complexos** em que os dados precisam ser tratados em caminhos diferentes em paralelo.
2. **Fontes e destinos variados**
    - N√£o se limita ao ecossistema AWS (S3, Glue Data Catalog, Redshift, Kinesis).
    - Suporta bancos de dados externos (MySQL, SQL Server, Oracle), servi√ßos concorrentes (BigQuery, Snowflake, Azure SQL) e at√© integra√ß√µes SaaS (Salesforce, LinkedIn, PayPal, QuickBooks).
    - Isso refor√ßa o Glue como uma ferramenta **agn√≥stica** para pipelines de dados.
3. **Transforma√ß√µes visuais e customizadas**
    - Alterar esquemas (dropar colunas, converter tipos, renomear campos).
    - Aplicar **filtros condicionais** diretamente na interface.
    - Fazer **joins, unions, agrega√ß√µes**.
    - Quando necess√°rio, voc√™ ainda pode inserir **transforma√ß√µes customizadas em PySpark**, aproveitando todo o poder do Apache Spark.
4. **Particionamento autom√°tico**
    - O Glue Studio entende **dados particionados** (por exemplo, em S3: `/ano=2024/mes=09/dia=30/`) e **otimiza automaticamente** a execu√ß√£o, processando apenas as parti√ß√µes relevantes.
    - Isso reduz custo e acelera o pipeline.
5. **Monitoramento e troubleshooting**
    - Possui um **painel visual de execu√ß√£o**, onde voc√™ enxerga cada n√≥ (fonte, transforma√ß√£o, destino) e v√™ seu status em tempo real.
    - Ajuda a identificar gargalos, erros e acompanhar performance.
---
##  Compara√ß√£o: Glue tradicional vs Glue Studio

|**Glue tradicional**|**Glue Studio**|
|---|---|
|Exige programa√ß√£o em PySpark|Interface visual ‚Äúdrag-and-drop‚Äù|
|Mais flex√≠vel para cen√°rios avan√ßados|Mais acess√≠vel e r√°pido para construir pipelines|
|Scripts lineares|DAGs paralelos e complexos|
|Bom para engenheiros de dados experientes|Democratiza ETL para analistas e cientistas de dados|

---
##  Onde ele se encaixa no exame AWS?
No exame de certifica√ß√£o (ex.: **AWS Solutions Architect** ou **Data Analytics Specialty**):
- Hoje, a maior parte das quest√µes ainda foca no **Glue ETL cl√°ssico** (jobs em Spark, DynamicFrames, crawlers, cat√°logo de dados).
- Mas o **Glue Studio** j√° √© visto pela AWS como a evolu√ß√£o natural do servi√ßo, e **certamente vai aparecer cada vez mais em provas futuras**, principalmente em perguntas sobre **facilidade de uso, pipelines visuais e integra√ß√£o com m√∫ltiplas fontes**.
---
üëâ Resumindo:  
O **Glue Studio** √© como se fosse a **‚Äúcamada visual e simplificada‚Äù do AWS Glue**, trazendo praticidade, suporte a m√∫ltiplas fontes externas e monitoramento integrado ‚Äî sem perder a possibilidade de usar Spark para casos avan√ßados.

---
## AWS Glue Data Quality (DQ)

O **AWS Glue Data Quality (DQ)** √© um recurso recente do Glue Studio que permite **avaliar automaticamente a qualidade dos dados** processados em pipelines ETL/ELT.  
Ele garante que dados que n√£o atendam a regras ou padr√µes definidos sejam **sinalizados** ou at√© mesmo **bloqueiem a execu√ß√£o** do job.

---
### Como funciona?
1. **Etapa dentro do workflow ETL**
    - Funciona como um **n√≥ adicional** em um job do Glue (assim como transforma√ß√µes, joins, filtros).
    - Pode ser configurado para:
        - **Falhar o job** caso regras sejam violadas.
        - **Apenas registrar alertas** no **Amazon CloudWatch**.
2. **Defini√ß√£o das regras de qualidade**
    - **Manual**: usando a linguagem **DQDL (Data Quality Definition Language)**.
    - **Autom√°tica**: o Glue pode **inferir regras a partir de um dataset confi√°vel** (‚Äúgolden dataset‚Äù), analisando:
        - Intervalos esperados.
        - Desvio padr√£o.
        - Cardinalidade.
        - Completeness (valores nulos ou faltantes).
        - Distribui√ß√µes.
3. **Resultados**
    - Voc√™ recebe relat√≥rios de conformidade: quais regras passaram ou falharam.
    - Esses relat√≥rios podem disparar alarmes no **CloudWatch**, ajudando na monitora√ß√£o e na governan√ßa de dados.
---
### Alguns exemplos de valida√ß√µes que podem ser criadas:
- **Contagem de linhas esperada**
    `RowCount BETWEEN 10_000 AND 15_000`
    üîé Garante que n√£o houve perda ou excesso de dados inesperado.
- **Valida√ß√£o de colunas obrigat√≥rias**
    `Column "cpf" IS NOT NULL`
    üîé Garante que nenhum registro esteja com campo cr√≠tico vazio.
- **Comprimento de string**
    `Length(Column "cep") BETWEEN 8 AND 9`
    üîé Checa integridade de formatos, como CEP ou telefone.
- **Desvio padr√£o esperado**
    `StdDev(Column "valor_transacao") < 5000`
    üîé Detecta valores fora do padr√£o (outliers ou poss√≠veis erros).
---
### Benef√≠cios
- **Confian√ßa nos dados** ‚Üí Evita que dados ruins cheguem em an√°lises, ML ou dashboards.
- **Automa√ß√£o** ‚Üí Menos esfor√ßo manual para criar valida√ß√µes.
- **Governan√ßa** ‚Üí Permite auditoria clara e centralizada.
- **Integra√ß√£o nativa** ‚Üí 100% integrado com Glue Studio, CloudWatch e outras ferramentas de observabilidade.
---
### Pontos de aten√ß√£o
- **Limites muito r√≠gidos** podem gerar **falsos positivos**, parando jobs sem necessidade.
- Estrat√©gia comum: primeiro configurar para apenas **logar alertas**, e s√≥ depois endurecer as regras para falhar jobs cr√≠ticos.
---
### Em exames da AWS
- Antes de 2023, **quase n√£o aparecia** em provas.
- A partir de **2024**, j√° √© mencionado no **AWS Data Analytics Specialty** e em updates de **Solutions Architect**.
- Quest√µes t√≠picas v√£o perguntar:
    - _‚ÄúComo validar automaticamente qualidade de dados em pipelines ETL no Glue?‚Äù_ ‚Üí Resposta: **Glue Data Quality (DQDL)**.
    - _‚ÄúComo evitar que dados incorretos sigam no pipeline?‚Äù_ ‚Üí Resposta: **falhar o job via regra de qualidade**.
---
üëâ Resumindo:  
O **Glue Data Quality** √© como um **‚Äúguardi√£o de qualidade‚Äù** dentro dos pipelines Glue. Ele pode **aprender regras automaticamente** ou **receber defini√ß√µes manuais (DQDL)**, e atua tanto de forma **preventiva** (falhando jobs) quanto **monitorada** (logando no CloudWatch).

---
## AWS Glue DataBrew

O **AWS Glue DataBrew** √© uma ferramenta **visual e sem c√≥digo** para **prepara√ß√£o e transforma√ß√£o de dados**.  
Ele √© voltado para analistas e engenheiros de dados que precisam **limpar, padronizar e enriquecer dados** antes de an√°lises, machine learning ou cargas em data lakes/data warehouses.

üëâ Pense nele como o **Excel turbo para Big Data**, s√≥ que com escalabilidade e integra√ß√£o com AWS.

---
### Principais caracter√≠sticas
1. **Interface visual (no-code)**
    - Permite aplicar transforma√ß√µes arrastando e clicando, sem precisar escrever c√≥digo Spark.
    - Reduz a curva de aprendizado para usu√°rios n√£o t√©cnicos.
2. **Transforma√ß√µes pr√©-definidas**
    - Mais de **250 transforma√ß√µes prontas**, incluindo:
        - Limpeza de valores nulos.
        - Padroniza√ß√£o de datas, n√∫meros e strings.
        - Enriquecimento de colunas (derivadas, splits, joins).
        - Normaliza√ß√£o de formatos.
        - Cria√ß√£o de campos calculados.
3. **Receitas (Recipes)**
    - Sequ√™ncias de transforma√ß√µes aplicadas a datasets.
    - Podem ser **reutilizadas em diferentes jobs e datasets**.
    - Compostas por **a√ß√µes de receita** (recipe actions).
    - Exemplo: a transforma√ß√£o **Nest to Map** agrupa v√°rias colunas em um JSON `{chave: valor}`.
4. **Suporte a regras de qualidade de dados**
    - Garante que os dados transformados sigam padr√µes.
    - Exemplo: validar faixas num√©ricas, formatos de string, colunas obrigat√≥rias.
5. **Integra√ß√µes com fontes e destinos**
    - Entrada: S3, Redshift, Snowflake, JDBC (bancos relacionais).
    - Sa√≠da: S3 (para posterior uso em Glue ETL, Athena, Redshift, ML, etc.).
6. **Seguran√ßa e Governan√ßa**
    - **IAM** ‚Üí controle de permiss√µes.
    - **KMS** ‚Üí criptografia em repouso.
    - **SSL/TLS** ‚Üí criptografia em tr√¢nsito.
    - **CloudWatch / CloudTrail** ‚Üí logs, auditoria e alarmes.
---
### Diferen√ßa entre **DataBrew** e **Glue ETL**

|**Aspecto**|**AWS Glue DataBrew**|**AWS Glue ETL (Spark)**|
|---|---|---|
|P√∫blico-alvo|Analistas de dados / usu√°rios sem c√≥digo|Engenheiros de dados / devs Spark|
|Tipo de uso|Transforma√ß√µes r√°pidas e visuais|Pipelines ETL complexos, escal√°veis e program√°veis|
|Linguagem|No-code (arrastar e soltar)|PySpark / Scala|
|Foco|Prepara√ß√£o de dados (limpeza, padroniza√ß√£o)|ETL/ELT completo (ingest√£o, transforma√ß√£o, carga)|
|Sa√≠da|Arquivos tratados no S3|S3, JDBC, Redshift, Kafka, etc.|
|Casos de uso t√≠picos|Normalizar datasets antes do ML, BI e dashboards|Pipelines de Big Data e Data Lakehouse|

---
### Casos de uso pr√°ticos
- Limpar dados de CRM ou ERP antes de carregar em um Data Lake.
- Padronizar formatos de datas e endere√ßos em datasets vindos de m√∫ltiplas fontes.
- Remover duplicatas e normalizar colunas para an√°lise em Redshift/Athena.
- Preparar datasets para **treinamento de modelos de Machine Learning** no SageMaker.
---
### No exame AWS
- Quest√µes podem perguntar:
    - _‚ÄúQual servi√ßo da AWS voc√™ usaria para preparar dados de forma visual, com mais de 250 transforma√ß√µes pr√©-definidas, sem precisar programar?‚Äù_ ‚Üí **AWS Glue DataBrew**.
    - _‚ÄúComo engenheiros de dados n√£o t√©cnicos podem padronizar datasets antes de an√°lises no Redshift ou ML?‚Äù_ ‚Üí **AWS Glue DataBrew**.
    - _‚ÄúQual servi√ßo permite criar **recipes** de transforma√ß√µes reutiliz√°veis em datasets?‚Äù_ ‚Üí **AWS Glue DataBrew**.

---
üëâ Em resumo:  
O **Glue DataBrew** √© a ferramenta da AWS para **democratizar o T do ETL**, permitindo que at√© quem n√£o sabe Spark ou SQL crie pipelines de limpeza e padroniza√ß√£o **visualmente** e com **boas pr√°ticas de governan√ßa**.

---
## Manuseio de [[PII]] no AWS Glue DataBrew

No **AWS Glue DataBrew**, √© muito comum que os conjuntos de dados contenham **informa√ß√µes sens√≠veis** (como nome, CPF, RG, e-mail, telefone, n√∫mero de cart√£o de cr√©dito, etc.). O exame destaca que voc√™ precisa saber **quais transforma√ß√µes existem para lidar com esse tipo de dado**, garantindo conformidade com **LGPD (Brasil), GDPR (Europa), HIPAA (EUA)** e outras normas de privacidade.
### T√©cnicas suportadas pelo DataBrew para PII:
1. **Substitui√ß√£o (Substitution)**
    - Troca os valores originais por identificadores artificiais (ex: substituir nomes por IDs ou n√∫meros rand√¥micos).
    - Exemplo: ‚ÄúJo√£o Silva‚Äù ‚Üí ‚ÄúUser_12345‚Äù.
2. **Embaralhamento (Shuffle)**
    - Mistura os valores de uma coluna entre diferentes registros.
    - Exemplo: embaralhar os CPFs de modo que n√£o correspondam mais aos indiv√≠duos originais.
    - **Obs:** Pode quebrar integridade de dados se usado sem cuidado.
3. **Criptografia determin√≠stica (Deterministic Encryption)**
    - O mesmo valor de entrada sempre gera o mesmo valor criptografado.
    - Exemplo: ‚Äú123-45-6789‚Äù ‚Üí ‚ÄúXyT98f‚Äù.
    - Permite ainda realizar **joins** ou **compara√ß√µes**, j√° que a sa√≠da √© consistente.
4. **Criptografia probabil√≠stica (Probabilistic Encryption)**
    - O mesmo valor de entrada pode resultar em **diferentes valores criptografados**.
    - Exemplo: ‚Äú123-45-6789‚Äù ‚Üí ‚ÄúAb9@d2‚Äù em uma inst√¢ncia e ‚ÄúKl7$0f‚Äù em outra.
    - Melhora a seguran√ßa, mas impede compara√ß√µes diretas.
5. **Remo√ß√£o (Deletion)**
    - Elimina completamente os campos PII do dataset.
    - √â a forma mais segura (se n√£o precisar da informa√ß√£o).
6. **Mascaramento (Masking)**
    - Oculta parte da informa√ß√£o, geralmente mantendo apenas um fragmento √∫til.
    - Exemplo: n√∫mero de cart√£o de cr√©dito ‚Äú1234 5678 9012 3456‚Äù ‚Üí ‚Äú**** **** **** 3456‚Äù.
7. **Hashing (Hash)**
    - Aplica uma fun√ß√£o de **hash criptogr√°fico** (ex: SHA-256) para anonimizar os dados.
    - Diferen√ßa da criptografia: n√£o h√° ‚Äúdecrypt‚Äù (irrevers√≠vel).
    - Exemplo: e-mails hashados para evitar reidentifica√ß√£o.
---
‚úÖ **Resumo para exame**:  
O **Glue DataBrew** oferece m√∫ltiplas transforma√ß√µes para lidar com PII. O candidato deve lembrar que:
- **M√°scara e Hash** ‚Üí anonimiza√ß√£o;
- **Criptografia** ‚Üí preserva seguran√ßa com possibilidade de revers√£o (dependendo do tipo);
- **Substitui√ß√£o/Shuffle** ‚Üí t√©cnicas de ofusca√ß√£o;
- **Exclus√£o** ‚Üí op√ß√£o mais r√≠gida, mas muitas vezes necess√°ria.
---
## O que s√£o os **Glue Workflows**?
- S√£o **ferramentas de orquestra√ß√£o dentro do Glue**.
- Permitem encadear **jobs ETL, crawlers e triggers** para criar pipelines mais complexos.
- **N√£o** s√£o equivalentes ao Step Functions, MWAA (Airflow) ou outros orquestradores mais gerais ‚Äî s√≥ trabalham **dentro do Glue**.

üëâ Pense neles como **um ‚Äúmini-orquestrador‚Äù especializado em ETL no Glue**.

---
### Como funcionam?
- Voc√™ monta um fluxo de ETL com **depend√™ncias e paralelismos**.
- Exemplo cl√°ssico:
    1. Job A ‚Üí remove duplicatas
    2. Job B ‚Üí corrige n√∫meros de telefone
    3. Quando **A e B terminarem**, executa Job C ‚Üí atualiza o schema
Ou seja, voc√™ pode rodar jobs em **paralelo** e depois consolidar.

---
### Gatilhos (Triggers)

Um Workflow do Glue √© controlado por **gatilhos**. Os principais s√£o:
1. **Por tempo (Schedule)**
    - Tipo _cron job_
    - Exemplo: ‚Äúexecutar todo dia √†s 3h da manh√£‚Äù
2. **Sob demanda**
    - Acionado manualmente pelo console ou via API
3. **Por evento (EventBridge)**
    - Exemplo:
        - Arquivo chegou no S3 ‚Üí dispara workflow
        - Pode ser **evento √∫nico** ou **lote** (esperar X arquivos em Y minutos antes de iniciar)

---
### Ponto-chave para exame
- **Glue Workflows** = apenas ETL dentro do Glue
- **Step Functions / MWAA** = orquestra√ß√£o geral, integrando m√∫ltiplos servi√ßos
- **Glue Workflow pode integrar com EventBridge**, mas n√£o orquestra servi√ßos fora do Glue.
---
üìå **Resumo de uma linha para memorizar**:  
üëâ _Glue Workflow orquestra ETL dentro do Glue, com jobs, crawlers e triggers baseados em tempo, evento ou sob demanda._