#tema/database 
##  O que √© o Redshift
- **Data Warehouse totalmente gerenciado** da AWS.
- Escala de **terabytes a petabytes**.
	- **Extremamente dimension√°vel e r√°pido** ‚Üí Redshift permite escalar armazenamento e computa√ß√£o de forma independente (especialmente com RA3 e Serverless), mantendo performance mesmo em cargas muito grandes.
	- **Utiliza Machine Learning** ‚Üí para otimizar execu√ß√£o de queries, prever tempo de consultas curtas (SQA), ajustar automaticamente o Workload Management e at√© otimizar cache e planos de execu√ß√£o.
	- **Executa consultas massivamente paralelas (MPP)** ‚Üí o processamento √© distribu√≠do entre m√∫ltiplos n√≥s em paralelo, acelerando an√°lises em petabytes de dados.
- Focado em [**OLAP (Online Analytical Processing)**](obsidian://open?vault=aws_data_engenier&file=AWS-Data-Engineer-Certificacao%2FData-Engineering-Fundamentals%2FOLAP%20VS%20OLTP), n√£o em OLTP (transa√ß√µes).
- Permite consultas r√°pidas em grandes volumes de dados usando **SQL padr√£o**, com suporte a **ODBC/JDBC**.
- Integra-se nativamente com o ecossistema AWS (S3, Glue, Athena, QuickSight).
- **Custo-efetivo**: paga-se pelos n√≥s e pelo armazenamento, com possibilidade de **pausar e retomar clusters**.
- Utiliza o modo colunar de trabalhar OLAP
---
## MPP
**MPP (Massively Parallel Processing)** √© um modelo de processamento de dados onde uma consulta ou tarefa √© **dividida em partes menores** e distribu√≠da entre **m√∫ltiplos n√≥s (m√°quinas)** que trabalham **em paralelo**.

‚û°Ô∏è No contexto de data warehouses como o Amazon Redshift:
- Cada **n√≥** do cluster processa uma parte dos dados.
- O **l√≠der (leader node)** coordena, divide a query e depois agrega os resultados parciais.
- Isso permite que consultas que levariam horas em um √∫nico servidor sejam resolvidas em **segundos ou minutos**.

üîë Caracter√≠sticas do MPP:
- **Escalabilidade horizontal** ‚Üí basta adicionar n√≥s ao cluster para processar mais dados.
- **Alta performance** ‚Üí aproveita processamento paralelo de CPU, mem√≥ria e I/O.
- **Ideal para OLAP** (consultas anal√≠ticas complexas sobre grandes volumes de dados).

üëâ Exemplo simples:  
Imagine consultar 1 PB de dados.
- Em um servidor √∫nico (processamento serial), ele teria que ler tudo sozinho.
- Em um cluster MPP com 100 n√≥s, cada n√≥ processa **1% dos dados em paralelo**, e o leader node junta os resultados finais.
---
##  Como entrega performance
- **MPP (Massively Parallel Processing)**: divide consultas em m√∫ltiplos n√≥s que processam em paralelo.
- **Armazenamento colunar**: otimizado para consultas anal√≠ticas (scans, agrega√ß√µes).
- **Compress√£o de colunas**: reduz espa√ßo e acelera leitura.
- **Machine Learning (Auto-tuning)**: Redshift usa ML para ajustar planos de execu√ß√£o e caching.
---
##  Casos de uso comuns
- **Moderniza√ß√£o de data warehouse** legados (substitui Oracle/Teradata, etc.).
- **An√°lises globais de vendas**.
- **Dados hist√≥ricos de mercado financeiro** (ex.: negocia√ß√µes de a√ß√µes).
- **Publicidade digital**: an√°lise de impress√µes, cliques, convers√µes.
- **Gaming analytics**: agrega√ß√£o de eventos e m√©tricas de jogadores.
- **An√°lise de tend√™ncias sociais**.
- **Unifica√ß√£o de Data Warehouse + Data Lake** (Redshift + Spectrum + S3).
## Arquitetura do Amazon Redshift 
![[Pasted image 20250910183954.png]]
### 1. **Cluster**
- Unidade principal de infraestrutura do Redshift.
- Cont√©m **um n√≥ l√≠der** e **1 a 128 n√≥s de computa√ß√£o** (dependendo do tipo/ra3, dc2, etc.).
- Pode hospedar **um ou mais bancos de dados**.
- √â a camada **vis√≠vel para o usu√°rio**: voc√™ se conecta ao cluster e n√£o diretamente aos n√≥s.
---
### 2. **N√≥ L√≠der (Leader Node)**
- Atua como **controlador e coordenador**.
- Fun√ß√µes principais:
    1. Receber consultas dos clientes (via JDBC/ODBC, API, console, etc.).
    2. **Analisar e gerar o plano de execu√ß√£o** (query execution plan).
    3. Distribuir etapas do plano para os **n√≥s de computa√ß√£o**.
    4. Agregar resultados intermedi√°rios e retornar ao cliente.
- N√£o armazena dados do usu√°rio (apenas metadados e cat√°logo do sistema).
- √â um **ponto √∫nico de entrada** para o cluster.
---
### 3. **N√≥s de Computa√ß√£o (Compute Nodes)**
- Onde os **dados do usu√°rio s√£o realmente armazenados**.
- Cada n√≥ tem:
    - **CPU dedicada**
    - **Mem√≥ria**
    - **Armazenamento em disco**
- Fun√ß√µes:
    - Executar etapas do plano de execu√ß√£o enviadas pelo n√≥ l√≠der.
    - Trocar dados entre si (quando necess√°rio, ex: joins entre tabelas).
    - Enviar resultados intermedi√°rios de volta ao n√≥ l√≠der.

---
### 4. **Fatias (Slices)**
- Cada n√≥ de computa√ß√£o √© dividido em **fatias**.
- Cada fatia recebe **uma por√ß√£o dos dados** e da carga de trabalho.
- O n√∫mero de fatias depende do tipo de n√≥ (ex.: um n√≥ `ra3.16xlarge` tem muito mais fatias do que um `ra3.4xlarge`).
- **Processamento paralelo real** ‚Üí cada fatia executa parte da query sobre seu peda√ßo de dados.
üìå Exemplo:
- Um cluster com **4 n√≥s de computa√ß√£o**.
- Cada n√≥ √© dividido em **8 fatias**.
- Total: **32 fatias trabalhando em paralelo**, cada uma processando parte da tabela.
---
## Como o fluxo funciona
1. Cliente envia uma query (SQL).
2. O **n√≥ l√≠der**:
    - Analisa a query.
    - Cria o plano de execu√ß√£o.
    - Distribui tarefas para cada fatia nos n√≥s de computa√ß√£o.
3. **Fatias** processam os dados localmente em paralelo.
4. Resultados intermedi√°rios s√£o enviados de volta ao **n√≥ l√≠der**.
5. O n√≥ l√≠der agrega e retorna o resultado final ao cliente.
---
##  Por que isso √© importante?
- **MPP (Massively Parallel Processing)** √© implementado justamente por essa divis√£o em n√≥s e fatias.
- Essa arquitetura garante:
    - Escalabilidade ‚Üí adiciona n√≥s = mais fatias = mais paralelismo.
    - Performance ‚Üí processamento distribu√≠do.
    - Flexibilidade ‚Üí voc√™ escolhe o tipo e tamanho dos n√≥s conforme custo/performance desejados.
---
üëâ Resumindo:
- **Cluster** = cont√™iner geral.
- **Leader Node** = c√©rebro (planejamento + coordena√ß√£o).
- **Compute Nodes** = m√∫sculos (armazenamento + execu√ß√£o).
- **Slices** = subdivis√µes dentro dos m√∫sculos (paralelismo real).

---
## Redshift Spectrum
- Permite **consultar dados diretamente no S3**, sem precisar carreg√°-los para o cluster.
- Suporta **exabytes de dados n√£o estruturados ou semiestruturados** (CSV, Parquet, JSON, etc.).
- **Escalabilidade horizontal**: processa consultas em paralelo em centenas de n√≥s ‚ÄúSpectrum‚Äù.
- Separa **compute** (Redshift cluster) de **storage** (S3).
- Suporte a **compress√£o Gzip/Snappy**.
---
## Durabilidade e disponibilidade
- **Replica√ß√£o dentro do cluster** (n√≥s de dados replicados).
- **Backups autom√°ticos no S3**.
- **Snapshots ass√≠ncronos replicados para outra regi√£o** (DR).
- **Troca autom√°tica de discos/n√≥s com falha**.
- Antes: cluster limitado a **1 zona de disponibilidade (AZ)**.
- Agora: **Multi-AZ dispon√≠vel para n√≥s RA3** ‚Üí mais resili√™ncia e HA.
---
## Escalabilidade no Redshift
- **Escala vertical e horizontal sob demanda**.
- Durante scaling:
    - Novo cluster √© criado em paralelo.
    - Cluster antigo **ainda pode ser lido**.
    - Quando pronto, o **CNAME √© trocado** para o novo cluster.
    - Pode haver **alguns minutos de downtime** no redirecionamento.
    - Dados s√£o movidos em paralelo para os novos n√≥s de compute.
---
## Distribution Styles (como os dados s√£o distribu√≠dos entre n√≥s)
- **AUTO**: Redshift decide com base no tamanho da tabela.
- **EVEN**: distribui√ß√£o round-robin das linhas entre slices.
- **KEY**: linhas s√£o distribu√≠das com base em uma coluna (ideal para joins).
- **ALL**: a tabela inteira √© replicada em todos os n√≥s (bom para tabelas pequenas e lookup tables).

üí° Escolher bem o distribution style √© **cr√≠tico para performance** ‚Äî minimiza data shuffling entre n√≥s durante joins.

---
![[Pasted image 20250910184559.png]]
![[Pasted image 20250910184614.png]]
![[Pasted image 20250910184622.png]]
---
## Importa√ß√£o e Exporta√ß√£o de dados
- **COPY (importa√ß√£o)**
    - Carrega dados de forma **paralelizada e eficiente**.
    - Suporta fontes: **S3, EMR, DynamoDB, hosts remotos**.
    - S3 exige manifest file + IAM role.
    - Pode **descriptografar** dados durante o load.
    - Suporta **compress√£o (gzip, lzop, bzip2)**.
    - Usa **SSL com acelera√ß√£o por hardware**.
    - Pode aplicar **compress√£o autom√°tica** com base no perfil do dataset.
    - Melhor pr√°tica: carregar **narrow tables (muitas linhas, poucas colunas)** em uma √∫nica transa√ß√£o COPY.
- **UNLOAD (exporta√ß√£o)**
    - Exporta dados do Redshift para arquivos no **S3**.
    - Gera arquivos em paralelo, de acordo com os n√≥s do cluster.
- **Integra√ß√µes recentes**
    - **Enhanced VPC Routing**: tr√°fego for√ßado pela VPC para maior controle.
    - **Auto-copy do S3**: integra√ß√£o automatizada.
    - **Aurora zero-ETL**: integra√ß√£o nativa Aurora ‚Üí Redshift.
    - **Streaming ingestion**: ingest√£o direta de streams do **Kinesis Data Streams** ou **MSK (Kafka)**.
---
## Cross-region Snapshot Copy (para DR e backup)
Quando o cluster √© criptografado com KMS:
1. **Na regi√£o de destino**:
    - Criar chave KMS.
    - Criar um **snapshot copy grant** ligado a essa chave.
2. **Na regi√£o de origem**:
    - Ativar c√≥pia de snapshots para o copy grant criado.
‚û°Ô∏è Assim, snapshots s√£o replicados entre regi√µes de forma segura.
---

## üîπ DBLINK e integra√ß√£o com PostgreSQL

Como Redshift √© baseado em PostgreSQL, √© poss√≠vel usar **dblink / postgres_fdw** para integrar e sincronizar dados:

``` SQL
CREATE EXTENSION postgres_fdw; 
CREATE EXTENSION dblink;  

CREATE SERVER foreign_server FOREIGN DATA WRAPPER postgres_fdw 
OPTIONS (host '<redshift_ip>',
 port '<port>',
 dbname '<db>',
 sslmode 'require');  

CREATE USER MAPPING FOR <rds_pg_user> SERVER foreign_server OPTIONS 
(user '<redshift_user>',
password '<pwd>');
```

- Permite copiar ou sincronizar dados entre **RDS PostgreSQL** e **Redshift**.
- Bom para **migra√ß√£o gradual** ou **integra√ß√£o de sistemas legados**.
---
## Resumo dos pontos-chave
- **Escala**: vertical/horizontal, com migra√ß√£o autom√°tica (downtime m√≠nimo).
- **Distribui√ß√£o**: escolha correta do distribution style √© vital para performance.
- **Ingest√£o/exporta√ß√£o**: COPY e UNLOAD s√£o eficientes; agora com op√ß√µes de streaming e Aurora zero-ETL.
- **Backup/DR**: snapshots podem ser replicados entre regi√µes com KMS.
- **Integra√ß√£o**: DBLINK facilita migra√ß√£o/integra√ß√£o com PostgreSQL.
---
# Integra√ß√µes do Amazon Redshift com outros servi√ßos da AWS

### 1. **Amazon S3**
- **Integra√ß√£o principal**:
    - `COPY` ‚Üí Importa dados do S3 para tabelas no Redshift.
    - `UNLOAD` ‚Üí Exporta resultados de queries do Redshift para S3 (em CSV, Parquet, etc.).
    - **Redshift Spectrum** ‚Üí Permite consultar **diretamente dados no S3** (em formatos como Parquet, ORC, JSON, CSV), sem precisar carreg√°-los para dentro do cluster.
- **Uso t√≠pico:**
    - Ingest√£o de dados brutos em um _data lake_.
    - Armazenamento hist√≥rico barato e quase ilimitado.
    - Integra√ß√£o com Athena, Glue, EMR.
---
### 2. **Amazon DynamoDB**
- **Integra√ß√£o via `COPY`:**
    - Voc√™ pode carregar uma tabela inteira do DynamoDB diretamente para dentro do Redshift.
    - √ötil para **sincronizar dados transacionais** (OLTP ‚Üí OLAP).
- **Uso t√≠pico:**
    - Empresas que usam DynamoDB como banco de opera√ß√µes transacionais (e-commerce, jogos, IoT).
    - Depois precisam analisar dados hist√≥ricos/anal√≠ticos no Redshift.
---
### 3. **Amazon EMR e Amazon EC2**
- **Integra√ß√£o via SSH + `COPY`:**
    - Redshift pode importar dados diretamente de clusters EMR (Hadoop/Spark) ou inst√¢ncias EC2.
    - Os dados precisam estar acess√≠veis via arquivo/host remoto.
- **Uso t√≠pico:**
    - Processar dados em **Spark/EMR** e depois carregar resultados no Redshift.
    - Pipelines h√≠bridos (pr√©-processamento em EC2/EMR, an√°lise em Redshift).
---
### 4. **AWS Data Pipeline**
- **Integra√ß√£o para orquestra√ß√£o de dados:**
    - Automatiza movimenta√ß√£o, transforma√ß√£o e carga de dados.
    - Pode mover dados entre **S3, DynamoDB, RDS, Redshift** e outros servi√ßos.
- **Uso t√≠pico:**
    - ETL programado para carregar dados diariamente/horariamente em Redshift.
    - Pipelines que unem dados de m√∫ltiplas fontes.
---
### 5. **AWS Database Migration Service (DMS)**
- **Integra√ß√£o para migra√ß√£o cont√≠nua ou inicial:**
    - Permite migrar bancos de dados existentes para Redshift.
    - Suporta migra√ß√£o com **replica√ß√£o em tempo real (CDC ‚Äì Change Data Capture)**.
- **Uso t√≠pico:**
    - Migrar de um data warehouse legado (Oracle, Teradata, SQL Server) para Redshift.
    - Manter sincroniza√ß√£o cont√≠nua enquanto a empresa faz a transi√ß√£o.
---
## Workload Management (WLM)
√â o mecanismo do Redshift para **gerenciar e priorizar cargas de trabalho concorrentes**.  
Em vez de todas as queries competirem igualmente pelos recursos do cluster, o WLM organiza as queries em **filas (queues)**, cada uma com **regras de execu√ß√£o, limites de concorr√™ncia e prioridades**.
### Por que isso √© necess√°rio?
- Sem WLM, queries grandes (ex.: um join de bilh√µes de linhas) poderiam bloquear queries r√°pidas (ex.: SELECT de 100 linhas).
- O WLM evita gargalos, garantindo que **consultas curtas e importantes n√£o fiquem presas atr√°s de consultas longas**.
### Como funciona
1. **Filas de execu√ß√£o (query queues):**
    - Cada fila pode ser configurada com:
        - N√∫mero m√°ximo de queries concorrentes.
        - Aloca√ß√£o de mem√≥ria.
        - Tempo limite.
        - Regras de prioridade.
2. **Classes de servi√ßo:**
    - Definem a qual fila cada query pertence.
    - Exemplo: consultas de BI ‚Üí fila 1, ETL batch ‚Üí fila 2.
3. **Execu√ß√£o:**
    - Queries entram na fila de acordo com regras (usu√°rio, grupo, tag, tipo de query).
    - Se a fila estiver cheia, queries aguardam.
    - O Redshift pode permitir **query hopping** (migrar queries de uma fila para outra).
---
# Tipos de WLM
### 1. **Manual WLM**
- Voc√™ configura manualmente:
    - At√© **8 filas**.
    - Concorr√™ncia, mem√≥ria e prioridades de cada fila.
- Exemplo:
    - Fila 1: at√© 5 queries curtas, timeout 60s.
    - Fila 2: at√© 3 queries pesadas de ETL, timeout 1h.
### 2. **Automatic WLM**
- O Redshift usa **machine learning** para:
    - Ajustar dinamicamente concorr√™ncia e mem√≥ria.
    - Criar at√© **8 filas autom√°ticas**.
    - Detectar queries curtas x longas e priorizar automaticamente.
---
### Recursos adicionais do WLM
- **Concurrency Scaling:** cria clusters tempor√°rios adicionais quando h√° excesso de queries.
- **Short Query Acceleration (SQA):** detecta queries curtas e as executa imediatamente em uma √°rea dedicada, sem esperar fila.
- **Query Monitoring Rules (QMR):** permite definir regras autom√°ticas (ex.: cancelar queries que usam >100 GB de mem√≥ria).
---
###  Benef√≠cios do WLM
- Melhor **tempo de resposta** para queries curtas.
- Menos **bloqueios e filas longas**.
- Mais **previsibilidade** para usu√°rios de BI e ETL.
- Possibilidade de **isolar workloads** (ex.: n√£o deixar um job batch derrubar os dashboards).
---
üìå **Resumo:**  
O **WLM √© o ‚Äúgerente de tr√¢nsito‚Äù do Redshift** ‚Üí decide quem vai primeiro, quem espera e quem usa mais pista (mem√≥ria/CPU).
## O que √© Concurrency Scaling no Redshift?
√â um recurso que permite ao Redshift **criar automaticamente clusters adicionais tempor√°rios** para lidar com picos de consultas simult√¢neas (especialmente **leitura**).
- Funciona como um **‚Äúclone tempor√°rio‚Äù** do seu cluster.
- Escala horizontalmente para processar queries em paralelo. 
- Quando a carga normaliza, esses clusters extras s√£o desligados.
---
## Por que √© importante?
- Sem ele ‚Üí consultas entram em fila quando h√° muitos usu√°rios simult√¢neos.
- Com ele ‚Üí o Redshift processa **praticamente ilimitadas consultas simult√¢neas**.
- Evita gargalos em cen√°rios de BI, dashboards e analytics.
---
## Como funciona na pr√°tica
1. Voc√™ habilita o recurso no cluster.
2. O Redshift detecta que uma fila do **Workload Management (WLM)** est√° congestionada.
3. Ele automaticamente **redireciona queries para um cluster de Concurrency Scaling**.
4. Assim, os usu√°rios n√£o percebem atraso.
‚ö° Detalhe: Voc√™ pode configurar **quais filas do WLM** podem ou n√£o usar o Concurrency Scaling.
---
##  Custos
- Voc√™ recebe **1 hora gratuita de Concurrency Scaling por dia para cada hora de uso de cluster**.
- Se ultrapassar isso ‚Üí cobra por segundo de uso extra.
- Por isso, √© importante selecionar **quais queries realmente merecem** esse recurso (ex.: dashboards de executivos, e n√£o ETL batch).
---
## Benef√≠cios
- **Elasticidade autom√°tica** ‚Üí escala para milhares de usu√°rios de BI sem precisar superprovisionar o cluster.
- **Controle granular** ‚Üí decide quais workloads podem escalar.
- **Integra√ß√£o com WLM** ‚Üí s√≥ filas espec√≠ficas aproveitam.
- **Escalabilidade transparente** ‚Üí usu√°rios finais nem percebem.    
---
## Compara√ß√£o r√°pida
- **Resizing (Elastic Resize / RA3 Managed Storage):** muda o tamanho do cluster (mais n√≥s, mais capacidade total).
- **Concurrency Scaling:** cria c√≥pias tempor√°rias para aguentar rajadas de consultas.  
    üëâ Eles se complementam, mas n√£o s√£o a mesma coisa.
---
üìå **Resumo estilo exame:**  
O **Concurrency Scaling** permite ao Redshift **criar clusters tempor√°rios sob demanda** para lidar com picos de consultas simult√¢neas, de forma autom√°tica e transparente, reduzindo filas de espera. Voc√™ controla via **Workload Management (WLM)** quais filas podem usar o recurso.

---
#  Resizing de Clusters
- **Elastic Resize**:
    - R√°pido (minutos).
    - Adiciona/remove n√≥s do mesmo tipo.
    - Pode trocar tipo de n√≥, mas cria novo cluster (causa downtime curto).
    - Limite: alguns tipos s√≥ permitem dobrar ou reduzir pela metade.
- **Classic Resize**:
    - Lento (horas/dias).
    - Muda tipo/n√∫mero de n√≥s.
    - Snapshot + restore ‚Üí cluster fica dispon√≠vel em modo leitura.
    - √ötil para grandes mudan√ßas (ex.: dc2 ‚Üí ra3).
---
## **VACUUM no Redshift**

O comando `VACUUM` √© usado para **otimizar tabelas**.  
Ele lida com dois pontos principais:
- **Recuperar espa√ßo** das linhas exclu√≠das.
- **Restaurar a ordem de classifica√ß√£o** da tabela (segundo a sort key).
## Tipos de VACUUM
1. **VACUUM FULL (padr√£o)**
    - Reordena todas as linhas **e** recupera espa√ßo das linhas exclu√≠das.
2. **VACUUM DELETE ONLY**
    - Recupera apenas espa√ßo de linhas deletadas.
    - N√£o reordena a tabela.
3. **VACUUM SORT ONLY**
    - Apenas reordena as linhas da tabela.
    - N√£o recupera espa√ßo em disco.
4. **VACUUM REINDEX**
    - Recria os √≠ndices intercalados (interleaved sort keys).
    - Reanalisa a distribui√ß√£o de valores e depois executa um VACUUM completo.
üëâ Importante: VACUUM pode ser **pesado em clusters grandes** ‚Üí boas pr√°ticas s√£o agendar em per√≠odos de baixa carga ou automatizar com **AWS Glue / Lambda / Scripts**.
---
# üîπ Novos recursos
- **RA3 nodes (managed storage)**
    - Escalam compute e storage de forma independente.
    - Baseados em SSD.
- **Data lake export**
    - UNLOAD para S3 em **Parquet** (at√© 2x mais r√°pido, 6x menos espa√ßo).
    - Compat√≠vel com Spectrum, Athena, EMR, SageMaker.
    - Suporta **particionamento autom√°tico**.
- **Spatial data types** ‚Üí GEOMETRY e GEOGRAPHY.
- **Cross-region data sharing** ‚Üí compartilhar dados ao vivo entre clusters Redshift (sem c√≥pia).
    - Suporta entre contas, entre regi√µes.
    - Exige RA3.
---
## ML 
![[Pasted image 20250910185701.png]]

---
## **Antipadr√µes do Redshift**
Situa√ß√µes em que **n√£o usar Redshift**:
- **Conjuntos de dados pequenos** ‚Üí melhor usar **RDS** ou at√© **Aurora**.
- **Workloads OLTP (transacionais)** ‚Üí melhor **RDS** ou **DynamoDB**.
- **Dados n√£o estruturados** ‚Üí usar **S3 + Glue/EMR** para ETL antes de Redshift.
- **Armazenamento de blobs (arquivos grandes bin√°rios)** ‚Üí n√£o guardar no Redshift; guardar no **S3** e apenas manter refer√™ncias no warehouse.
---
## Seguran√ßa
- **HSM (Hardware Security Module)**: para criptografia avan√ßada.
- Migra√ß√£o de cluster n√£o criptografado ‚Üí criar novo cluster criptografado e mover dados.
- **Controle de acesso via SQL**:

  ```SQL
 GRANT SELECT ON table foo TO bob; REVOKE INSERT ON table bar FROM alice;
 ```
- Integra√ß√£o com IAM, KMS, VPC, Enhanced VPC Routing.
---
#  Redshift Serverless
- **Sem clusters fixos** ‚Üí endpoint serverless.
- **Escalabilidade autom√°tica** ‚Üí paga s√≥ pelo uso.
- Ideal para:
    - Workloads vari√°veis ou espor√°dicas.
    - Ambientes de desenvolvimento/teste.
    - An√°lises ad-hoc (BI, queries explorat√≥rias).
- Usa ML para balancear custo vs performance.
---
‚úÖ **Resumo final**:  
Amazon Redshift hoje n√£o √© s√≥ um **DW em cluster** ‚Äî ele virou uma **plataforma h√≠brida** que suporta:
- Clusters cl√°ssicos (com resize el√°stico/cl√°ssico).
- **Serverless** para workloads imprevis√≠veis.
- Integra√ß√£o total com o ecossistema AWS (S3, DynamoDB, Aurora, Kinesis, EMR, SageMaker).
- Recursos modernos: RA3 nodes, Spectrum, Lake Export, Cross-Region Sharing.
- Ferramentas de gest√£o de workload (WLM, SQA, Concurrency Scaling).